embedding size is:  20
Max Batch Size is:  20
Starting round 1
userId: 0 training_loss:  4.92512815378913
userId: 1 training_loss:  4.652927925351149
userId: 2 training_loss:  4.4370720374838335
userId: 3 training_loss:  5.897099871002085
userId: 4 training_loss:  5.97166563562585
userId: 5 training_loss:  2.2148983349319566
userId: 6 training_loss:  2.667087924439403
userId: 7 training_loss:  5.473252892398774
userId: 8 training_loss:  4.071604715421445
userId: 9 training_loss:  5.773436557957204
userId: 10 training_loss:  2.372393644177599
userId: 11 training_loss:  4.295830789072553
userId: 12 training_loss:  6.247232464995074
userId: 13 training_loss:  5.578323331678989
userId: 14 training_loss:  4.430454069807026
userId: 15 training_loss:  3.124921327268061
userId: 16 training_loss:  3.6030762729772148
userId: 17 training_loss:  3.223580670944466
userId: 18 training_loss:  5.1797384405974976
userId: 19 training_loss:  6.554781231748528
userId: 20 training_loss:  6.465405541391519
Evaluating model...
computed_loss: 3.52185836457474
Starting round 2
userId: 0 training_loss:  5.541619290400865
userId: 1 training_loss:  5.317414857433699
userId: 2 training_loss:  3.8449598476323863
userId: 3 training_loss:  5.252711966585649
userId: 4 training_loss:  4.212994339223992
userId: 5 training_loss:  1.774067842366864
userId: 6 training_loss:  2.597499523326093
userId: 7 training_loss:  4.863720220998156
userId: 8 training_loss:  5.736940678212133
userId: 9 training_loss:  4.400154460792615
userId: 10 training_loss:  2.8383853268369954
userId: 11 training_loss:  4.278026684334508
userId: 12 training_loss:  4.919301492944234
userId: 13 training_loss:  5.9576430442039054
userId: 14 training_loss:  4.538061756879587
userId: 15 training_loss:  2.91567502876813
userId: 16 training_loss:  3.9003161520678296
userId: 17 training_loss:  3.034026900922587
userId: 18 training_loss:  4.280495718077406
userId: 19 training_loss:  5.847871743067814
userId: 20 training_loss:  4.678517688949073
Evaluating model...
computed_loss: 3.4931143599012078
Starting round 3
userId: 0 training_loss:  5.573453619944705
userId: 1 training_loss:  5.205952917745205
userId: 2 training_loss:  4.758901826051936
userId: 3 training_loss:  5.16187103058987
userId: 4 training_loss:  3.898427399610179
userId: 5 training_loss:  1.8939456995164299
userId: 6 training_loss:  2.5964516154032435
userId: 7 training_loss:  5.477017428696516
userId: 8 training_loss:  6.742189749165642
userId: 9 training_loss:  4.228095469863666
userId: 10 training_loss:  2.377399671945832
userId: 11 training_loss:  4.018618839724392
userId: 12 training_loss:  5.2093344105873545
userId: 13 training_loss:  5.847953849821103
userId: 14 training_loss:  4.4970826219965065
userId: 15 training_loss:  3.0920861099693697
userId: 16 training_loss:  4.642835240845061
userId: 17 training_loss:  2.818926106670273
userId: 18 training_loss:  5.102628808241528
userId: 19 training_loss:  5.322204143462821
userId: 20 training_loss:  5.103870924574563
Evaluating model...
computed_loss: 3.3542421367396456
Starting round 4
userId: 0 training_loss:  5.774828975383265
userId: 1 training_loss:  5.314165741300207
userId: 2 training_loss:  3.5450615718419867
userId: 3 training_loss:  5.585401425215608
userId: 4 training_loss:  4.768349867634461
userId: 5 training_loss:  1.4707811824017523
userId: 6 training_loss:  1.9763491809453815
userId: 7 training_loss:  6.713434986995409
userId: 8 training_loss:  6.220736745905538
userId: 9 training_loss:  4.780837517127506
userId: 10 training_loss:  1.89091339175743
userId: 11 training_loss:  4.308900944457245
userId: 12 training_loss:  5.048207858399343
userId: 13 training_loss:  5.797449717921224
userId: 14 training_loss:  3.46327258235331
userId: 15 training_loss:  2.767356955658654
userId: 16 training_loss:  4.132192397176089
userId: 17 training_loss:  3.053668247360358
userId: 18 training_loss:  4.057980253750184
userId: 19 training_loss:  5.120906117899704
userId: 20 training_loss:  5.1174811911166085
Evaluating model...
computed_loss: 3.1313444929143137
Starting round 5
userId: 0 training_loss:  6.659527176311924
userId: 1 training_loss:  5.41406756451869
userId: 2 training_loss:  4.0282897000092
userId: 3 training_loss:  5.633844247884723
userId: 4 training_loss:  4.343259400174729
userId: 5 training_loss:  1.4404172782569036
userId: 6 training_loss:  1.7800283083352197
userId: 7 training_loss:  5.542743216053172
userId: 8 training_loss:  6.909506422988104
userId: 9 training_loss:  5.095349671712901
userId: 10 training_loss:  2.0917549306569225
userId: 11 training_loss:  4.11782965685156
userId: 12 training_loss:  5.163091251994706
userId: 13 training_loss:  6.612418624150732
userId: 14 training_loss:  4.055782436934751
userId: 15 training_loss:  2.46074554380722
userId: 16 training_loss:  3.511602954817765
userId: 17 training_loss:  2.5016408268099113
userId: 18 training_loss:  4.716568054542184
userId: 19 training_loss:  5.606193496033807
userId: 20 training_loss:  5.751796552012424
Evaluating model...
computed_loss: 2.8697557496643062
Starting round 6
userId: 0 training_loss:  6.212191155024534
userId: 1 training_loss:  5.423926583061333
userId: 2 training_loss:  3.952946518009143
userId: 3 training_loss:  5.366589885051587
userId: 4 training_loss:  4.234757260923321
userId: 5 training_loss:  1.3397040245714047
userId: 6 training_loss:  1.9944625869162198
userId: 7 training_loss:  5.982702096551311
userId: 8 training_loss:  7.069252234218512
userId: 9 training_loss:  5.480459631977942
userId: 10 training_loss:  1.712698441294012
userId: 11 training_loss:  4.030735912597521
userId: 12 training_loss:  5.4825222100987006
userId: 13 training_loss:  5.591139130433177
userId: 14 training_loss:  5.060005154786827
userId: 15 training_loss:  2.5227366671644895
userId: 16 training_loss:  3.6821246001176755
userId: 17 training_loss:  1.8629728025041061
userId: 18 training_loss:  4.0531301789767324
userId: 19 training_loss:  5.886204589719812
userId: 20 training_loss:  5.536633252471908
Evaluating model...
computed_loss: 2.858489115171036
Starting round 7
userId: 0 training_loss:  6.02797522284766
userId: 1 training_loss:  5.356980209562784
userId: 2 training_loss:  3.59709704999333
userId: 3 training_loss:  4.798874759283786
userId: 4 training_loss:  4.9218928339001
userId: 5 training_loss:  1.3111823772271012
userId: 6 training_loss:  1.8029300580781857
userId: 7 training_loss:  5.341761148598033
userId: 8 training_loss:  5.667226056276997
userId: 9 training_loss:  5.591681435025564
userId: 10 training_loss:  1.5701384289999383
userId: 11 training_loss:  6.084207793846041
userId: 12 training_loss:  4.751651423752392
userId: 13 training_loss:  6.400630318587217
userId: 14 training_loss:  4.420481895019291
userId: 15 training_loss:  2.5494375798099744
userId: 16 training_loss:  4.4054600352093605
userId: 17 training_loss:  2.547943536379818
userId: 18 training_loss:  3.9781382514899684
userId: 19 training_loss:  5.8517833474157745
userId: 20 training_loss:  5.126069271602149
Evaluating model...
computed_loss: 2.7299855835226103
Starting round 8
userId: 0 training_loss:  6.378046475429645
userId: 1 training_loss:  4.929555831236307
userId: 2 training_loss:  3.81031539092847
userId: 3 training_loss:  4.497333978557231
userId: 4 training_loss:  4.165435008338419
userId: 5 training_loss:  1.2707120861070982
userId: 6 training_loss:  1.8628942788831027
userId: 7 training_loss:  5.14390387680606
userId: 8 training_loss:  6.760121713819774
userId: 9 training_loss:  3.95592917878702
userId: 10 training_loss:  1.5679236182263911
userId: 11 training_loss:  3.9164644992062754
userId: 12 training_loss:  5.8500474255947825
userId: 13 training_loss:  5.300126066698587
userId: 14 training_loss:  4.695419234438369
userId: 15 training_loss:  2.3720977711663984
userId: 16 training_loss:  3.5316439728464517
userId: 17 training_loss:  2.265838569275723
userId: 18 training_loss:  4.356496270572197
userId: 19 training_loss:  4.522612437211511
userId: 20 training_loss:  4.999891412757858
Evaluating model...
computed_loss: 2.470899325243176
Starting round 9
userId: 0 training_loss:  6.028174306047635
userId: 1 training_loss:  4.931100541434643
userId: 2 training_loss:  4.1476288021987795
userId: 3 training_loss:  5.313651640224175
userId: 4 training_loss:  3.9858241284087725
userId: 5 training_loss:  1.2636635709502941
userId: 6 training_loss:  1.865791791756105
userId: 7 training_loss:  4.775689498225017
userId: 8 training_loss:  6.249646443606798
userId: 9 training_loss:  4.288652034383907
userId: 10 training_loss:  1.5631546684580773
userId: 11 training_loss:  3.641308284858769
userId: 12 training_loss:  5.0129605446122545
userId: 13 training_loss:  5.828166996043745
userId: 14 training_loss:  4.39321673754876
userId: 15 training_loss:  2.3309686696948217
userId: 16 training_loss:  3.7027909690400462
userId: 17 training_loss:  2.3842423080141657
userId: 18 training_loss:  3.295483866434286
userId: 19 training_loss:  5.543532344127184
userId: 20 training_loss:  5.047738746351813
Evaluating model...
computed_loss: 2.3544983842372336
Starting round 10
userId: 0 training_loss:  5.728204317057465
userId: 1 training_loss:  5.862786068695574
userId: 2 training_loss:  3.461457355876944
userId: 3 training_loss:  5.027762575556816
userId: 4 training_loss:  4.425456008402037
userId: 5 training_loss:  1.097153135257385
userId: 6 training_loss:  1.819037408505324
userId: 7 training_loss:  5.34811742809387
userId: 8 training_loss:  6.298458017046018
userId: 9 training_loss:  4.330837597034646
userId: 10 training_loss:  1.555618515819472
userId: 11 training_loss:  3.344010644073009
userId: 12 training_loss:  4.8014788077090005
userId: 13 training_loss:  5.055785345464714
userId: 14 training_loss:  3.7461266838312155
userId: 15 training_loss:  1.9784657332645872
userId: 16 training_loss:  3.8822664072185615
userId: 17 training_loss:  2.1042263848585794
userId: 18 training_loss:  3.5650668366763973
userId: 19 training_loss:  4.939789459232591
userId: 20 training_loss:  4.826020770556557
Evaluating model...
computed_loss: 2.2336071970768168
Starting round 11
userId: 0 training_loss:  6.36929391671423
userId: 1 training_loss:  4.982139792873643
userId: 2 training_loss:  3.4343123779887343
userId: 3 training_loss:  5.372226273786993
userId: 4 training_loss:  3.4610098850986164
userId: 5 training_loss:  1.052931759393576
userId: 6 training_loss:  1.8767687315444452
userId: 7 training_loss:  4.804885517522114
userId: 8 training_loss:  6.051533718364497
userId: 9 training_loss:  3.820733150116367
userId: 10 training_loss:  1.5533901095690388
userId: 11 training_loss:  4.248170544874674
userId: 12 training_loss:  4.245787768478595
userId: 13 training_loss:  4.829300449852591
userId: 14 training_loss:  3.936157904973407
userId: 15 training_loss:  2.4917896916875324
userId: 16 training_loss:  3.888009717722368
userId: 17 training_loss:  2.38238201326761
userId: 18 training_loss:  4.6850316354124555
userId: 19 training_loss:  4.578933884335694
userId: 20 training_loss:  3.825306886965405
Evaluating model...
computed_loss: 2.322844140063744
Starting round 12
userId: 0 training_loss:  6.387476398036734
userId: 1 training_loss:  5.795485814762374
userId: 2 training_loss:  3.9217651900237955
userId: 3 training_loss:  4.854643237210888
userId: 4 training_loss:  3.4897731515808443
userId: 5 training_loss:  1.13395103034556
userId: 6 training_loss:  1.9274247769667832
userId: 7 training_loss:  4.824164633115481
userId: 8 training_loss:  6.040517983639566
userId: 9 training_loss:  5.067343057846956
userId: 10 training_loss:  1.3677836924968516
userId: 11 training_loss:  3.8332663257505786
userId: 12 training_loss:  4.942423041332427
userId: 13 training_loss:  5.788807242423174
userId: 14 training_loss:  3.2725978777212257
userId: 15 training_loss:  2.6547878692369262
userId: 16 training_loss:  3.1020424777755684
userId: 17 training_loss:  1.8562507460028663
userId: 18 training_loss:  4.166506666553159
userId: 19 training_loss:  6.032825856129874
userId: 20 training_loss:  4.958099749716726
Evaluating model...
computed_loss: 2.3509971635006575
Starting round 13
userId: 0 training_loss:  6.271519440799736
userId: 1 training_loss:  4.4662385718112585
userId: 2 training_loss:  4.037568576497761
userId: 3 training_loss:  4.511867829240272
userId: 4 training_loss:  4.003263103634277
userId: 5 training_loss:  1.0404870441462055
userId: 6 training_loss:  1.9265594177444096
userId: 7 training_loss:  4.644512576593236
userId: 8 training_loss:  5.570324862365444
userId: 9 training_loss:  3.338896720590997
userId: 10 training_loss:  1.4339770189959737
userId: 11 training_loss:  3.366410586504261
userId: 12 training_loss:  4.228203502075463
userId: 13 training_loss:  5.818732601846177
userId: 14 training_loss:  3.537492326040595
userId: 15 training_loss:  2.2358962603987753
userId: 16 training_loss:  3.8192964190085013
userId: 17 training_loss:  2.2318564753344825
userId: 18 training_loss:  3.534243334120039
userId: 19 training_loss:  5.656774176801911
userId: 20 training_loss:  4.581620965524392
Evaluating model...
computed_loss: 2.257188401080638
Starting round 14
userId: 0 training_loss:  5.670801588216282
userId: 1 training_loss:  4.922163186175838
userId: 2 training_loss:  3.702710477922961
userId: 3 training_loss:  4.151713118275877
userId: 4 training_loss:  4.073299524700146
userId: 5 training_loss:  1.072169946241273
userId: 6 training_loss:  1.9441959285305785
userId: 7 training_loss:  5.934620041956277
userId: 8 training_loss:  5.708902926606385
userId: 9 training_loss:  4.451243097073699
userId: 10 training_loss:  1.5073930144431753
userId: 11 training_loss:  4.489641106182195
userId: 12 training_loss:  4.451882747372084
userId: 13 training_loss:  5.376864353550113
userId: 14 training_loss:  3.7002465259841992
userId: 15 training_loss:  2.4335602866805774
userId: 16 training_loss:  3.0854209688919343
userId: 17 training_loss:  2.1540252529805017
userId: 18 training_loss:  3.8314382635595727
userId: 19 training_loss:  4.714884500517912
userId: 20 training_loss:  5.173285691449552
Evaluating model...
computed_loss: 2.0613402031878887
Starting round 15
userId: 0 training_loss:  5.355443937969976
userId: 1 training_loss:  5.689855723282582
userId: 2 training_loss:  3.9155931732537352
userId: 3 training_loss:  4.891607956792958
userId: 4 training_loss:  4.352478076519782
userId: 5 training_loss:  1.0347547562081802
userId: 6 training_loss:  1.8059308485625813
userId: 7 training_loss:  5.121098291745058
userId: 8 training_loss:  6.1870600431926785
userId: 9 training_loss:  4.3279127909642545
userId: 10 training_loss:  1.4879384019577198
userId: 11 training_loss:  3.9648350749628802
userId: 12 training_loss:  4.700534354508324
userId: 13 training_loss:  5.089127961152692
userId: 14 training_loss:  3.2791643560819366
userId: 15 training_loss:  2.3137912442230197
userId: 16 training_loss:  3.173400889296253
userId: 17 training_loss:  2.3754027744346295
userId: 18 training_loss:  3.406314099573142
userId: 19 training_loss:  5.166262225147662
userId: 20 training_loss:  4.419927559762999
Evaluating model...
computed_loss: 2.0365523506824204
Starting round 16
userId: 0 training_loss:  5.536811130784242
userId: 1 training_loss:  4.829887311569739
userId: 2 training_loss:  3.494091047348924
userId: 3 training_loss:  4.241639814147886
userId: 4 training_loss:  3.9156604490723472
userId: 5 training_loss:  1.1677711174502885
userId: 6 training_loss:  1.8683247110588475
userId: 7 training_loss:  4.562881477753178
userId: 8 training_loss:  6.2030292704745955
userId: 9 training_loss:  3.1500019968657305
userId: 10 training_loss:  1.462415516955784
userId: 11 training_loss:  3.3033657124754137
userId: 12 training_loss:  4.689172501639076
userId: 13 training_loss:  5.260684425049538
userId: 14 training_loss:  4.3732566950823415
userId: 15 training_loss:  2.3951576655694895
userId: 16 training_loss:  3.2963145418126745
userId: 17 training_loss:  2.2017165480389385
userId: 18 training_loss:  3.194597025033243
userId: 19 training_loss:  4.274521522525811
userId: 20 training_loss:  3.606349125154683
Evaluating model...
computed_loss: 1.9387528683749533
Starting round 17
userId: 0 training_loss:  5.04849883323838
userId: 1 training_loss:  4.834801413655788
userId: 2 training_loss:  3.7146636446098
userId: 3 training_loss:  4.675536514928283
userId: 4 training_loss:  4.068679922329365
userId: 5 training_loss:  0.9496313757999015
userId: 6 training_loss:  1.7083331179719736
userId: 7 training_loss:  4.529116541619735
userId: 8 training_loss:  5.678608126866584
userId: 9 training_loss:  3.5245290820357646
userId: 10 training_loss:  1.4197804444704611
userId: 11 training_loss:  3.0583424512654376
userId: 12 training_loss:  4.865051780042633
userId: 13 training_loss:  4.569500088313655
userId: 14 training_loss:  4.028026822225584
userId: 15 training_loss:  2.11384519838167
userId: 16 training_loss:  3.570866643735621
userId: 17 training_loss:  2.3297656436077396
userId: 18 training_loss:  3.380106761492685
userId: 19 training_loss:  3.9938225319503955
userId: 20 training_loss:  4.601764482364186
Evaluating model...
computed_loss: 1.9261602792860568
Starting round 18
userId: 0 training_loss:  5.6539581671863886
userId: 1 training_loss:  4.825461046943579
userId: 2 training_loss:  2.9788638489653216
userId: 3 training_loss:  5.196374422514982
userId: 4 training_loss:  3.5127577812739057
userId: 5 training_loss:  1.099615249082337
userId: 6 training_loss:  1.7946006055836208
userId: 7 training_loss:  4.5588084575371415
userId: 8 training_loss:  5.918365934505667
userId: 9 training_loss:  3.0546651112797893
userId: 10 training_loss:  1.4425991263492872
userId: 11 training_loss:  3.852915880356643
userId: 12 training_loss:  4.166574231056383
userId: 13 training_loss:  5.064050336400263
userId: 14 training_loss:  3.1882313436271863
userId: 15 training_loss:  2.2415852453263967
userId: 16 training_loss:  3.2786833877915056
userId: 17 training_loss:  2.456615709696301
userId: 18 training_loss:  3.5923512829980444
userId: 19 training_loss:  3.615452766221195
userId: 20 training_loss:  4.902412647808764
Evaluating model...
computed_loss: 1.8383386038372151
Starting round 19
userId: 0 training_loss:  5.179679605999592
userId: 1 training_loss:  4.865802255727312
userId: 2 training_loss:  4.474388095790739
userId: 3 training_loss:  4.246674294678563
userId: 4 training_loss:  3.384876439340605
userId: 5 training_loss:  1.0862503799283638
userId: 6 training_loss:  1.6956511853561982
userId: 7 training_loss:  3.9007042634533065
userId: 8 training_loss:  5.894349560693832
userId: 9 training_loss:  3.3427273533866497
userId: 10 training_loss:  1.3010263598985525
userId: 11 training_loss:  3.6607924815605366
userId: 12 training_loss:  3.9215162848297873
userId: 13 training_loss:  4.999208192772057
userId: 14 training_loss:  3.4453939980387434
userId: 15 training_loss:  2.3112373062856477
userId: 16 training_loss:  2.79050045447614
userId: 17 training_loss:  2.2372441717868696
userId: 18 training_loss:  4.425004419103962
userId: 19 training_loss:  3.9837581858369027
userId: 20 training_loss:  4.805826809024838
Evaluating model...
computed_loss: 1.8609592639788928
Starting round 20
userId: 0 training_loss:  6.299720797129542
userId: 1 training_loss:  4.302261905085734
userId: 2 training_loss:  3.6654789295776675
userId: 3 training_loss:  4.576782708781363
userId: 4 training_loss:  3.555402121519658
userId: 5 training_loss:  1.0443021071226029
userId: 6 training_loss:  1.6297066227468804
userId: 7 training_loss:  4.04211691796306
userId: 8 training_loss:  5.686940538512651
userId: 9 training_loss:  3.372134952484676
userId: 10 training_loss:  1.34819473466577
userId: 11 training_loss:  3.839495328856816
userId: 12 training_loss:  4.838289228073738
userId: 13 training_loss:  5.075586629766185
userId: 14 training_loss:  3.9235844423611774
userId: 15 training_loss:  2.3008782431505397
userId: 16 training_loss:  3.78107961697827
userId: 17 training_loss:  2.060586456174134
userId: 18 training_loss:  3.269236399671289
userId: 19 training_loss:  3.8890241603967697
userId: 20 training_loss:  4.179918387024837
Evaluating model...
computed_loss: 1.8349312091129841
Starting round 21
userId: 0 training_loss:  5.861632036682378
userId: 1 training_loss:  4.701420430344336
userId: 2 training_loss:  3.3282395564406584
userId: 3 training_loss:  4.122361387037108
userId: 4 training_loss:  4.400444526735349
userId: 5 training_loss:  1.1350347161356784
userId: 6 training_loss:  1.6815926118120808
userId: 7 training_loss:  4.389755737613194
userId: 8 training_loss:  7.316523525577727
userId: 9 training_loss:  3.728876344381816
userId: 10 training_loss:  1.2410750350305402
userId: 11 training_loss:  3.334667283586081
userId: 12 training_loss:  4.858766613640623
userId: 13 training_loss:  5.202596596983758
userId: 14 training_loss:  3.0157135689706056
userId: 15 training_loss:  2.3447649358672438
userId: 16 training_loss:  3.381136157181841
userId: 17 training_loss:  2.457139098519795
userId: 18 training_loss:  3.476328268156415
userId: 19 training_loss:  4.406785977706059
userId: 20 training_loss:  4.243740805939952
Evaluating model...
computed_loss: 1.7915496594993625
Starting round 22
userId: 0 training_loss:  5.840691423408249
userId: 1 training_loss:  5.1275254062648035
userId: 2 training_loss:  3.3297706364499775
userId: 3 training_loss:  4.583764005155027
userId: 4 training_loss:  3.3089931400952173
userId: 5 training_loss:  0.9296894064354551
userId: 6 training_loss:  1.7803329416426767
userId: 7 training_loss:  4.585088080720415
userId: 8 training_loss:  5.936984514548811
userId: 9 training_loss:  3.3545966296865593
userId: 10 training_loss:  1.3038052208508972
userId: 11 training_loss:  3.4369149681529443
userId: 12 training_loss:  3.4938074904083267
userId: 13 training_loss:  5.737653356090304
userId: 14 training_loss:  3.5743123100375613
userId: 15 training_loss:  2.252346322305475
userId: 16 training_loss:  3.2354207175748106
userId: 17 training_loss:  2.3018361534825553
userId: 18 training_loss:  3.47856156576625
userId: 19 training_loss:  4.8290535241406705
userId: 20 training_loss:  4.427343000146104
Evaluating model...
computed_loss: 1.898579344662704
Starting round 23
userId: 0 training_loss:  5.3465486622833165
userId: 1 training_loss:  4.436504111051886
userId: 2 training_loss:  3.2052958243302854
userId: 3 training_loss:  4.404281346145352
userId: 4 training_loss:  3.5329788370094013
userId: 5 training_loss:  1.0922313916589261
userId: 6 training_loss:  1.785757377747761
userId: 7 training_loss:  4.971360261655714
userId: 8 training_loss:  6.17171516164689
userId: 9 training_loss:  3.3577662902060426
userId: 10 training_loss:  1.2617591390818759
userId: 11 training_loss:  3.5228416451875417
userId: 12 training_loss:  4.845628759773362
userId: 13 training_loss:  5.05141463819497
userId: 14 training_loss:  3.4586151777926673
userId: 15 training_loss:  1.8597196724132636
userId: 16 training_loss:  2.681411051850813
userId: 17 training_loss:  2.0466928177908055
userId: 18 training_loss:  4.169899649322818
userId: 19 training_loss:  4.5472584680368735
userId: 20 training_loss:  4.046617675666945
Evaluating model...
computed_loss: 1.6016700560784942
Starting round 24
userId: 0 training_loss:  5.307763593386814
userId: 1 training_loss:  4.454017896133896
userId: 2 training_loss:  4.305156937687181
userId: 3 training_loss:  4.784495506804171
userId: 4 training_loss:  4.607228813361624
userId: 5 training_loss:  0.9184683238357781
userId: 6 training_loss:  1.9990357653183064
userId: 7 training_loss:  3.8163955048124847
userId: 8 training_loss:  5.599733410149619
userId: 9 training_loss:  4.088542047791852
userId: 10 training_loss:  1.2986855476850745
userId: 11 training_loss:  2.8440872386605776
userId: 12 training_loss:  4.055117459506344
userId: 13 training_loss:  4.444657541087828
userId: 14 training_loss:  3.331477283194341
userId: 15 training_loss:  2.2611372493806483
userId: 16 training_loss:  4.24072350649803
userId: 17 training_loss:  2.036573298576818
userId: 18 training_loss:  3.21510950872702
userId: 19 training_loss:  5.775363984326617
userId: 20 training_loss:  4.0505583853023115
Evaluating model...
computed_loss: 1.856315435857438
Starting round 25
userId: 0 training_loss:  5.37490195556329
userId: 1 training_loss:  5.137275280940149
userId: 2 training_loss:  3.1191147595948516
userId: 3 training_loss:  4.337494723957168
userId: 4 training_loss:  3.641966050594502
userId: 5 training_loss:  1.0666878012785208
userId: 6 training_loss:  1.7611181682222743
userId: 7 training_loss:  4.262380678779619
userId: 8 training_loss:  5.9031708903694335
userId: 9 training_loss:  3.2826270210217117
userId: 10 training_loss:  1.338230156978767
userId: 11 training_loss:  3.678283200742989
userId: 12 training_loss:  3.8797974793746244
userId: 13 training_loss:  4.517311790498418
userId: 14 training_loss:  3.5332885411126016
userId: 15 training_loss:  2.6402370644529003
userId: 16 training_loss:  2.85017563822459
userId: 17 training_loss:  1.9332056465321141
userId: 18 training_loss:  4.0210896040775275
userId: 19 training_loss:  4.078318368236548
userId: 20 training_loss:  5.1068711046872775
Evaluating model...
computed_loss: 1.7459105348567387
Starting round 26
userId: 0 training_loss:  4.909001058717886
userId: 1 training_loss:  4.552680904985353
userId: 2 training_loss:  3.051232444286372
userId: 3 training_loss:  3.715904397892884
userId: 4 training_loss:  3.567168052754176
userId: 5 training_loss:  1.0339597025674958
userId: 6 training_loss:  1.602156397870783
userId: 7 training_loss:  3.982589657658756
userId: 8 training_loss:  5.566697865549569
userId: 9 training_loss:  2.98876866459967
userId: 10 training_loss:  1.3375690603775854
userId: 11 training_loss:  3.2026000286782774
userId: 12 training_loss:  4.04620680758533
userId: 13 training_loss:  4.589696849676884
userId: 14 training_loss:  3.8179302957880976
userId: 15 training_loss:  2.2309648657614067
userId: 16 training_loss:  3.206156019833684
userId: 17 training_loss:  2.2274796658678566
userId: 18 training_loss:  3.9501160213391673
userId: 19 training_loss:  4.37496544028936
userId: 20 training_loss:  3.9306501866577612
Evaluating model...
computed_loss: 1.528208745311285
Starting round 27
userId: 0 training_loss:  4.86911934234349
userId: 1 training_loss:  4.530590832418904
userId: 2 training_loss:  3.700671673779145
userId: 3 training_loss:  4.089493131862123
userId: 4 training_loss:  3.530468180591529
userId: 5 training_loss:  1.038432978698252
userId: 6 training_loss:  1.4952893676940744
userId: 7 training_loss:  4.3419006271127625
userId: 8 training_loss:  5.848136779531425
userId: 9 training_loss:  3.1145470417589416
userId: 10 training_loss:  1.3667864925291826
userId: 11 training_loss:  2.7825418963504895
userId: 12 training_loss:  3.9514634111813662
userId: 13 training_loss:  4.428150902914932
userId: 14 training_loss:  3.5915549128080984
userId: 15 training_loss:  2.2832754292835107
userId: 16 training_loss:  2.951789120410538
userId: 17 training_loss:  2.151489245272659
userId: 18 training_loss:  3.5603800859325845
userId: 19 training_loss:  3.66831360737885
userId: 20 training_loss:  4.354352451022487
Evaluating model...
computed_loss: 1.518038582382005
Starting round 28
userId: 0 training_loss:  5.223088497169654
userId: 1 training_loss:  4.909108809952798
userId: 2 training_loss:  3.2906966420149866
userId: 3 training_loss:  4.422477700020051
userId: 4 training_loss:  2.981190398247775
userId: 5 training_loss:  0.9185465032278322
userId: 6 training_loss:  1.601592659567979
userId: 7 training_loss:  4.2948167644189486
userId: 8 training_loss:  5.920949605918385
userId: 9 training_loss:  3.3015454186549826
userId: 10 training_loss:  1.2152223897799823
userId: 11 training_loss:  2.688679262046803
userId: 12 training_loss:  4.839005265310172
userId: 13 training_loss:  4.970991563025407
userId: 14 training_loss:  4.176659296959061
userId: 15 training_loss:  2.477936326724586
userId: 16 training_loss:  3.6932288046727573
userId: 17 training_loss:  2.0401731229026634
userId: 18 training_loss:  3.377614456098209
userId: 19 training_loss:  4.23311798736823
userId: 20 training_loss:  4.491894377102101
Evaluating model...
computed_loss: 1.6230471948149972
Starting round 29
userId: 0 training_loss:  5.664305487574648
userId: 1 training_loss:  5.074891262736544
userId: 2 training_loss:  3.6574490309354055
userId: 3 training_loss:  3.8472776816524155
userId: 4 training_loss:  3.0834143198447976
userId: 5 training_loss:  0.9715431841739012
userId: 6 training_loss:  1.7140413575599542
userId: 7 training_loss:  4.960196840141281
userId: 8 training_loss:  5.954924385762938
userId: 9 training_loss:  2.9357885150451333
userId: 10 training_loss:  1.2913960913640372
userId: 11 training_loss:  4.131067618727455
userId: 12 training_loss:  3.750345234842606
userId: 13 training_loss:  4.648051514506016
userId: 14 training_loss:  4.68871088631654
userId: 15 training_loss:  2.202374291252151
userId: 16 training_loss:  3.844030235054658
userId: 17 training_loss:  2.459812558944233
userId: 18 training_loss:  4.016770001331402
userId: 19 training_loss:  4.194263665655452
userId: 20 training_loss:  4.273709376955137
Evaluating model...
computed_loss: 1.5720903534012545
Starting round 30
userId: 0 training_loss:  5.711485768553635
userId: 1 training_loss:  4.693949606903133
userId: 2 training_loss:  3.782433588270932
userId: 3 training_loss:  3.979453039507496
userId: 4 training_loss:  3.5512001815587224
userId: 5 training_loss:  0.9602313905540416
userId: 6 training_loss:  1.7710995466711936
userId: 7 training_loss:  4.253968118221751
userId: 8 training_loss:  5.744151954825644
userId: 9 training_loss:  2.5746376298272144
userId: 10 training_loss:  1.2470878752321888
userId: 11 training_loss:  3.632008543380844
userId: 12 training_loss:  3.4242041065880358
userId: 13 training_loss:  4.318306883243955
userId: 14 training_loss:  3.4503995002748065
userId: 15 training_loss:  2.333435459807015
userId: 16 training_loss:  2.638859395172296
userId: 17 training_loss:  2.13807806505322
userId: 18 training_loss:  3.2644604894809524
userId: 19 training_loss:  3.8333135024985596
userId: 20 training_loss:  4.169691764408104
Evaluating model...
computed_loss: 1.8156892284573805
Starting round 31
userId: 0 training_loss:  5.217271045920989
userId: 1 training_loss:  4.394792210822873
userId: 2 training_loss:  2.7312828083439347
userId: 3 training_loss:  3.8418954289463727
userId: 4 training_loss:  3.2625020038909023
userId: 5 training_loss:  1.1883478841481145
userId: 6 training_loss:  1.5951138188986038
userId: 7 training_loss:  3.965319146506205
userId: 8 training_loss:  5.749709684192061
userId: 9 training_loss:  3.2422825871510232
userId: 10 training_loss:  1.4037197766884446
userId: 11 training_loss:  3.3111831321200382
userId: 12 training_loss:  4.641788004824777
userId: 13 training_loss:  4.424227791500821
userId: 14 training_loss:  3.303364584533873
userId: 15 training_loss:  2.2348375414063772
userId: 16 training_loss:  2.9990527562609746
userId: 17 training_loss:  1.996598808831174
userId: 18 training_loss:  3.554217504523872
userId: 19 training_loss:  3.7576741307275796
userId: 20 training_loss:  5.117488267018332
Evaluating model...
computed_loss: 1.7931125916274102
Starting round 32
userId: 0 training_loss:  4.840776354499068
userId: 1 training_loss:  5.180676050461248
userId: 2 training_loss:  2.7485567361970626
userId: 3 training_loss:  4.061643645956993
userId: 4 training_loss:  4.306843114647551
userId: 5 training_loss:  1.0754361865000657
userId: 6 training_loss:  2.0774474267809167
userId: 7 training_loss:  4.293037960875757
userId: 8 training_loss:  6.306672534239013
userId: 9 training_loss:  3.134979320340107
userId: 10 training_loss:  1.2367852819918963
userId: 11 training_loss:  4.298051330288812
userId: 12 training_loss:  4.232325599453522
userId: 13 training_loss:  4.273711626618583
userId: 14 training_loss:  3.9992645807594926
userId: 15 training_loss:  2.097379782882266
userId: 16 training_loss:  2.9745612149245213
userId: 17 training_loss:  2.4528020203399903
userId: 18 training_loss:  3.0782460065507706
userId: 19 training_loss:  4.26183099729151
userId: 20 training_loss:  3.749285470952187
Evaluating model...
computed_loss: 1.4482650861832487
Starting round 33
userId: 0 training_loss:  5.115041512844871
userId: 1 training_loss:  4.425219918175892
userId: 2 training_loss:  3.677650669749253
userId: 3 training_loss:  4.074695755844654
userId: 4 training_loss:  3.387669692117357
userId: 5 training_loss:  1.0837318922069519
userId: 6 training_loss:  1.4975448242979548
userId: 7 training_loss:  4.244965250867482
userId: 8 training_loss:  6.648550360343504
userId: 9 training_loss:  3.516249949433319
userId: 10 training_loss:  1.242416540776627
userId: 11 training_loss:  4.135303635551791
userId: 12 training_loss:  4.050417654020296
userId: 13 training_loss:  4.920819883131378
userId: 14 training_loss:  3.2761276558150847
userId: 15 training_loss:  2.025102689238291
userId: 16 training_loss:  2.705498716238794
userId: 17 training_loss:  2.25196612909134
userId: 18 training_loss:  3.5480449688246205
userId: 19 training_loss:  3.3596918297655867
userId: 20 training_loss:  4.105852355674081
Evaluating model...
computed_loss: 1.6088495545930104
Starting round 34
userId: 0 training_loss:  5.663367834548064
userId: 1 training_loss:  4.752879409406286
userId: 2 training_loss:  3.4532230038353715
userId: 3 training_loss:  4.739905932378084
userId: 4 training_loss:  3.5320590660999223
userId: 5 training_loss:  1.127424657636303
userId: 6 training_loss:  1.7449343687905938
userId: 7 training_loss:  3.7135801296431667
userId: 8 training_loss:  5.46966974343147
userId: 9 training_loss:  3.0830383277338265
userId: 10 training_loss:  1.3435041837692396
userId: 11 training_loss:  2.71781044881496
userId: 12 training_loss:  3.999440539888122
userId: 13 training_loss:  4.550156132173227
userId: 14 training_loss:  3.6966593284585954
userId: 15 training_loss:  2.1071075234644177
userId: 16 training_loss:  3.23272305949948
userId: 17 training_loss:  2.123357138314481
userId: 18 training_loss:  3.5322100436230017
userId: 19 training_loss:  3.8965814091777333
userId: 20 training_loss:  4.111717356954516
Evaluating model...
computed_loss: 1.6221363165241904
Starting round 35
userId: 0 training_loss:  5.569535603557145
userId: 1 training_loss:  5.181935557695652
userId: 2 training_loss:  2.784167964174139
userId: 3 training_loss:  3.5855426746867662
userId: 4 training_loss:  3.6195688453726396
userId: 5 training_loss:  1.067344738065923
userId: 6 training_loss:  1.7971187018617076
userId: 7 training_loss:  4.5977910642320445
userId: 8 training_loss:  5.670364346040134
userId: 9 training_loss:  3.091708799163402
userId: 10 training_loss:  1.3030750813327805
userId: 11 training_loss:  4.463696058395182
userId: 12 training_loss:  3.844439587644517
userId: 13 training_loss:  4.199319854370788
userId: 14 training_loss:  3.797708178806211
userId: 15 training_loss:  2.399921468343918
userId: 16 training_loss:  3.7600941131667347
userId: 17 training_loss:  2.3402342307962343
userId: 18 training_loss:  3.2671941457239235
userId: 19 training_loss:  3.672450089181382
userId: 20 training_loss:  3.661052656160179
Evaluating model...
computed_loss: 1.5309758653514378
Starting round 36
userId: 0 training_loss:  5.244286784752952
userId: 1 training_loss:  4.690467370754373
userId: 2 training_loss:  3.620796682637299
userId: 3 training_loss:  3.6834015782127922
userId: 4 training_loss:  3.460375601760623
userId: 5 training_loss:  1.2303877877255431
userId: 6 training_loss:  1.5461899342958043
userId: 7 training_loss:  4.313045701101985
userId: 8 training_loss:  5.604347525944301
userId: 9 training_loss:  3.1276324540970037
userId: 10 training_loss:  1.1833202605392266
userId: 11 training_loss:  3.8168907686069806
userId: 12 training_loss:  3.359188643428986
userId: 13 training_loss:  4.278101057585641
userId: 14 training_loss:  3.4299002710474573
userId: 15 training_loss:  1.9842424450501093
userId: 16 training_loss:  2.7578607129512025
userId: 17 training_loss:  2.1782234247279995
userId: 18 training_loss:  3.3319310594602323
userId: 19 training_loss:  3.4803262646896322
userId: 20 training_loss:  4.351175139575864
Evaluating model...
computed_loss: 1.751529067699904
Starting round 37
userId: 0 training_loss:  4.995412522330177
userId: 1 training_loss:  4.437192815056585
userId: 2 training_loss:  3.658482313125704
userId: 3 training_loss:  4.12066003482288
userId: 4 training_loss:  3.535717815951714
userId: 5 training_loss:  1.1816593761863943
userId: 6 training_loss:  1.6383289425313259
userId: 7 training_loss:  4.329608270185349
userId: 8 training_loss:  5.428100781702388
userId: 9 training_loss:  3.9028194099364177
userId: 10 training_loss:  1.4402152861932476
userId: 11 training_loss:  3.1802733524449134
userId: 12 training_loss:  4.3656034530007375
userId: 13 training_loss:  4.515615149972788
userId: 14 training_loss:  2.975046998282034
userId: 15 training_loss:  2.4221880381334158
userId: 16 training_loss:  2.903660334303871
userId: 17 training_loss:  2.0407737042473024
userId: 18 training_loss:  3.0149572978116495
userId: 19 training_loss:  3.502200465946005
userId: 20 training_loss:  3.875690452917776
Evaluating model...
computed_loss: 1.5795474245143406
Starting round 38
userId: 0 training_loss:  5.417297674700281
userId: 1 training_loss:  4.429074431476244
userId: 2 training_loss:  3.187068020102136
userId: 3 training_loss:  4.141487828706206
userId: 4 training_loss:  3.0536488322930455
userId: 5 training_loss:  1.2221535580033402
userId: 6 training_loss:  1.4924787052368491
userId: 7 training_loss:  4.269969141350637
userId: 8 training_loss:  6.273349528116816
userId: 9 training_loss:  3.2447523404209706
userId: 10 training_loss:  1.3933010011186504
userId: 11 training_loss:  4.645422390885476
userId: 12 training_loss:  4.198167800631775
userId: 13 training_loss:  5.001450764846043
userId: 14 training_loss:  3.1585775962021794
userId: 15 training_loss:  2.3573652761786006
userId: 16 training_loss:  2.797456418227979
userId: 17 training_loss:  2.002654431395807
userId: 18 training_loss:  3.2550821314824416
userId: 19 training_loss:  3.9965873459649743
userId: 20 training_loss:  3.862592010357929
Evaluating model...
computed_loss: 1.7089684669060257
Starting round 39
userId: 0 training_loss:  5.619137170921782
userId: 1 training_loss:  4.549422871110851
userId: 2 training_loss:  3.0183537008899797
userId: 3 training_loss:  3.8197158986358977
userId: 4 training_loss:  3.427325284587622
userId: 5 training_loss:  1.1604368266857965
userId: 6 training_loss:  1.6123670657285563
userId: 7 training_loss:  4.171108482112674
userId: 8 training_loss:  6.139435973180065
userId: 9 training_loss:  4.9261758547024135
userId: 10 training_loss:  1.4376981860357427
userId: 11 training_loss:  3.4383893986328298
userId: 12 training_loss:  4.624041068418731
userId: 13 training_loss:  4.531834746041531
userId: 14 training_loss:  2.897256780336524
userId: 15 training_loss:  2.1520275402730222
userId: 16 training_loss:  2.8620373641849843
userId: 17 training_loss:  2.2912959607902095
userId: 18 training_loss:  3.2097826068022597
userId: 19 training_loss:  3.9880958462032035
userId: 20 training_loss:  3.723179632468958
Evaluating model...
computed_loss: 1.5870251834434188
Starting round 40
userId: 0 training_loss:  6.185128056491347
userId: 1 training_loss:  4.223383064025221
userId: 2 training_loss:  2.8000690343123664
userId: 3 training_loss:  3.9605010696305483
userId: 4 training_loss:  2.7438784045278615
userId: 5 training_loss:  1.0502200639724508
userId: 6 training_loss:  1.6797853999445302
userId: 7 training_loss:  4.162171586771729
userId: 8 training_loss:  6.45697175649327
userId: 9 training_loss:  3.2354327230350384
userId: 10 training_loss:  1.2648914552610182
userId: 11 training_loss:  3.062984406462233
userId: 12 training_loss:  3.4330308162544076
userId: 13 training_loss:  4.295218045207768
userId: 14 training_loss:  3.7741433616514852
userId: 15 training_loss:  1.8826757566706456
userId: 16 training_loss:  3.1593562871055516
userId: 17 training_loss:  2.0277094129692825
userId: 18 training_loss:  3.453860270572253
userId: 19 training_loss:  4.227423756919278
userId: 20 training_loss:  4.696928542899938
Evaluating model...
computed_loss: 1.467435991929537
Starting round 41
userId: 0 training_loss:  4.886350993443346
userId: 1 training_loss:  5.246262639678223
userId: 2 training_loss:  3.255605323597115
userId: 3 training_loss:  4.512521765428904
userId: 4 training_loss:  3.3358168803301487
userId: 5 training_loss:  0.9338716546566234
userId: 6 training_loss:  1.5604950218194216
userId: 7 training_loss:  4.559189418906143
userId: 8 training_loss:  5.361482191703621
userId: 9 training_loss:  3.7201382146955844
userId: 10 training_loss:  1.237358095109576
userId: 11 training_loss:  3.172824171884287
userId: 12 training_loss:  4.583174861078211
userId: 13 training_loss:  4.924343343542238
userId: 14 training_loss:  3.196292629381116
userId: 15 training_loss:  2.4324778148553703
userId: 16 training_loss:  3.2360165622907124
userId: 17 training_loss:  1.8901381994333977
userId: 18 training_loss:  3.392723540778708
userId: 19 training_loss:  4.213582624104029
userId: 20 training_loss:  3.9503880901465656
Evaluating model...
computed_loss: 1.461657209672203
Starting round 42
userId: 0 training_loss:  5.485089991055164
userId: 1 training_loss:  4.446541844519691
userId: 2 training_loss:  2.8776699620841426
userId: 3 training_loss:  4.105887125692648
userId: 4 training_loss:  2.6761755639200713
userId: 5 training_loss:  1.2017721931370697
userId: 6 training_loss:  1.7423434991587894
userId: 7 training_loss:  4.166556251608547
userId: 8 training_loss:  5.5320914901679
userId: 9 training_loss:  2.7586404448498114
userId: 10 training_loss:  1.3161564491427478
userId: 11 training_loss:  3.8578367310679305
userId: 12 training_loss:  4.220472562689597
userId: 13 training_loss:  4.807911864287327
userId: 14 training_loss:  5.109127583019031
userId: 15 training_loss:  2.2065161644462896
userId: 16 training_loss:  2.8605243216231915
userId: 17 training_loss:  2.1485244044250726
userId: 18 training_loss:  3.3486473302806212
userId: 19 training_loss:  4.308501982160666
userId: 20 training_loss:  3.625636689715833
Evaluating model...
computed_loss: 1.624440451479603
Starting round 43
userId: 0 training_loss:  5.342140753510933
userId: 1 training_loss:  4.725307670805709
userId: 2 training_loss:  3.2984642513369797
userId: 3 training_loss:  4.107368348512859
userId: 4 training_loss:  2.974162096324467
userId: 5 training_loss:  1.1317530568379008
userId: 6 training_loss:  1.6915645094867358
userId: 7 training_loss:  4.349185860691824
userId: 8 training_loss:  5.697711002192337
userId: 9 training_loss:  3.269588971850136
userId: 10 training_loss:  1.3501433268065886
userId: 11 training_loss:  4.032177167338109
userId: 12 training_loss:  4.596776179483139
userId: 13 training_loss:  4.555647614545161
userId: 14 training_loss:  3.477469350381287
userId: 15 training_loss:  2.0376577320151332
userId: 16 training_loss:  2.9835234077181054
userId: 17 training_loss:  2.1155843331785107
userId: 18 training_loss:  2.5883919593627436
userId: 19 training_loss:  4.842740384777365
userId: 20 training_loss:  3.8412781804038554
Evaluating model...
computed_loss: 1.5293002970839895
Starting round 44
userId: 0 training_loss:  4.955170019627099
userId: 1 training_loss:  4.690817905447733
userId: 2 training_loss:  2.9383002522780197
userId: 3 training_loss:  3.4597720610934575
userId: 4 training_loss:  3.0064664711218234
userId: 5 training_loss:  0.926007399052177
userId: 6 training_loss:  1.7549475159044357
userId: 7 training_loss:  4.29150009633721
userId: 8 training_loss:  5.365391313047443
userId: 9 training_loss:  2.9559621171498747
userId: 10 training_loss:  1.2618075798383084
userId: 11 training_loss:  3.000254363175572
userId: 12 training_loss:  3.570154042140196
userId: 13 training_loss:  4.231166980036607
userId: 14 training_loss:  3.3360155748959466
userId: 15 training_loss:  2.426636152873151
userId: 16 training_loss:  3.29482816949048
userId: 17 training_loss:  2.4092327292513978
userId: 18 training_loss:  3.0294933014814163
userId: 19 training_loss:  4.369759287686145
userId: 20 training_loss:  3.741141093332254
Evaluating model...
computed_loss: 1.5241731966361485
Starting round 45
userId: 0 training_loss:  5.035009735716748
userId: 1 training_loss:  4.865203290129154
userId: 2 training_loss:  3.1000457658539355
userId: 3 training_loss:  4.29544868462984
userId: 4 training_loss:  3.193030316663124
userId: 5 training_loss:  0.9099206875347597
userId: 6 training_loss:  1.848269114940663
userId: 7 training_loss:  3.9173491016280613
userId: 8 training_loss:  5.337445534899068
userId: 9 training_loss:  3.621550555224691
userId: 10 training_loss:  1.323285544970282
userId: 11 training_loss:  3.0861396050244743
userId: 12 training_loss:  4.095299607310295
userId: 13 training_loss:  4.45600595005589
userId: 14 training_loss:  3.5431015334591622
userId: 15 training_loss:  1.9646131382652012
userId: 16 training_loss:  3.0928501249545652
userId: 17 training_loss:  2.2330101997523633
userId: 18 training_loss:  3.7508383764460502
userId: 19 training_loss:  3.6775083198790286
userId: 20 training_loss:  5.1930958368543205
Evaluating model...
computed_loss: 1.4574308696739269
Starting round 46
userId: 0 training_loss:  5.127513087625272
userId: 1 training_loss:  4.407147490445334
userId: 2 training_loss:  3.302667024165521
userId: 3 training_loss:  3.6443124672002134
userId: 4 training_loss:  3.5389064174321554
userId: 5 training_loss:  1.248757544763319
userId: 6 training_loss:  1.6187525114715235
userId: 7 training_loss:  4.554439869890431
userId: 8 training_loss:  5.726856072108172
userId: 9 training_loss:  3.0218129914896954
userId: 10 training_loss:  1.3076571438371503
userId: 11 training_loss:  3.028070400821618
userId: 12 training_loss:  3.5936320706809304
userId: 13 training_loss:  3.9706668443765336
userId: 14 training_loss:  3.3292817336333136
userId: 15 training_loss:  2.0962597372105147
userId: 16 training_loss:  2.6708981585603317
userId: 17 training_loss:  1.838777792840908
userId: 18 training_loss:  2.930983760463448
userId: 19 training_loss:  3.598116102236704
userId: 20 training_loss:  3.876407299473051
Evaluating model...
computed_loss: 1.4481149923103462
Starting round 47
userId: 0 training_loss:  5.086451463911614
userId: 1 training_loss:  4.323874688437839
userId: 2 training_loss:  3.6407692717736864
userId: 3 training_loss:  4.064676384031497
userId: 4 training_loss:  2.7732963876493275
userId: 5 training_loss:  1.0477577590066802
userId: 6 training_loss:  1.5860135947149494
userId: 7 training_loss:  4.232149609108376
userId: 8 training_loss:  6.4492242353910525
userId: 9 training_loss:  3.109774371679311
userId: 10 training_loss:  1.3216930721569464
userId: 11 training_loss:  3.271442494278035
userId: 12 training_loss:  4.558488303284963
userId: 13 training_loss:  4.351594774076128
userId: 14 training_loss:  2.835718201926791
userId: 15 training_loss:  1.9374651479657232
userId: 16 training_loss:  2.8785536963284555
userId: 17 training_loss:  2.033224884951217
userId: 18 training_loss:  3.1211080828918987
userId: 19 training_loss:  3.7390299430368605
userId: 20 training_loss:  4.042143081420493
Evaluating model...
computed_loss: 1.6316664755323618
Starting round 48
userId: 0 training_loss:  5.365761332799556
userId: 1 training_loss:  4.450654570552504
userId: 2 training_loss:  2.6858325680195394
userId: 3 training_loss:  3.533857132561141
userId: 4 training_loss:  2.8605206952080424
userId: 5 training_loss:  1.0934419518353242
userId: 6 training_loss:  1.6576470849920777
userId: 7 training_loss:  4.617463425890035
userId: 8 training_loss:  5.77145227031174
userId: 9 training_loss:  3.007900080479023
userId: 10 training_loss:  1.3752201915823394
userId: 11 training_loss:  5.614323542048274
userId: 12 training_loss:  3.909874562939352
userId: 13 training_loss:  4.4163595033289695
userId: 14 training_loss:  3.1340821673952877
userId: 15 training_loss:  2.3963822460901962
userId: 16 training_loss:  4.334371635022584
userId: 17 training_loss:  1.979282263487671
userId: 18 training_loss:  3.195752220127455
userId: 19 training_loss:  4.026698677700545
userId: 20 training_loss:  4.455914680452297
Evaluating model...
computed_loss: 1.426425986937145
Starting round 49
userId: 0 training_loss:  5.248448223866306
userId: 1 training_loss:  4.419999229008524
userId: 2 training_loss:  2.9927134427993907
userId: 3 training_loss:  4.0114448909377645
userId: 4 training_loss:  3.8480224184856824
userId: 5 training_loss:  1.1797024091586747
userId: 6 training_loss:  1.8394913450569643
userId: 7 training_loss:  4.2370930156978925
userId: 8 training_loss:  6.4217778067096845
userId: 9 training_loss:  3.3147443790188973
userId: 10 training_loss:  1.2557749533014013
userId: 11 training_loss:  2.473498677730207
userId: 12 training_loss:  4.059259893866146
userId: 13 training_loss:  3.9630022305868216
userId: 14 training_loss:  3.652410890559485
userId: 15 training_loss:  2.0779768119259994
userId: 16 training_loss:  3.1234361669102415
userId: 17 training_loss:  2.118518924474501
userId: 18 training_loss:  3.642539237211544
userId: 19 training_loss:  3.503066544336724
userId: 20 training_loss:  4.781621935707812
Evaluating model...
computed_loss: 1.4161225661051864
Starting round 50
userId: 0 training_loss:  5.064620295199039
userId: 1 training_loss:  4.915711022974623
userId: 2 training_loss:  3.468462844408657
userId: 3 training_loss:  4.325759425214821
userId: 4 training_loss:  3.5982903860726525
userId: 5 training_loss:  1.0480912439531127
userId: 6 training_loss:  1.7442819166019956
userId: 7 training_loss:  4.59192413088004
userId: 8 training_loss:  5.4587273164601
userId: 9 training_loss:  3.419388483718766
userId: 10 training_loss:  1.4620245291098621
userId: 11 training_loss:  4.006737738344398
userId: 12 training_loss:  3.5401934169303706
userId: 13 training_loss:  3.8608898789746378
userId: 14 training_loss:  3.4907000756443542
userId: 15 training_loss:  2.2896742137477792
userId: 16 training_loss:  2.8806308867625665
userId: 17 training_loss:  2.42993502729869
userId: 18 training_loss:  2.970288576396345
userId: 19 training_loss:  3.595176440452623
userId: 20 training_loss:  3.7635824433264076
Evaluating model...
computed_loss: 1.4033493398362826
Starting round 51
userId: 0 training_loss:  5.253212706515716
userId: 1 training_loss:  4.295524291540444
userId: 2 training_loss:  3.2766818134995725
userId: 3 training_loss:  4.656891657580785
userId: 4 training_loss:  3.269973268852408
userId: 5 training_loss:  1.0544503665200762
userId: 6 training_loss:  1.6743407684147822
userId: 7 training_loss:  4.629017345891324
userId: 8 training_loss:  5.394403359583824
userId: 9 training_loss:  3.895203481665257
userId: 10 training_loss:  1.3264613462640535
userId: 11 training_loss:  3.452006537408786
userId: 12 training_loss:  3.4157176240578906
userId: 13 training_loss:  4.1004894212381195
userId: 14 training_loss:  3.134091796367444
userId: 15 training_loss:  2.2298798007230944
userId: 16 training_loss:  2.565055201220564
userId: 17 training_loss:  2.3299242575769386
userId: 18 training_loss:  3.6309194669553913
userId: 19 training_loss:  3.9984112287822384
userId: 20 training_loss:  3.7350174383788355
Evaluating model...
computed_loss: 1.2798554293239968
Starting round 52
userId: 0 training_loss:  4.829421125613445
userId: 1 training_loss:  4.612685245787935
userId: 2 training_loss:  2.9404024442841767
userId: 3 training_loss:  4.138603595098568
userId: 4 training_loss:  3.5130646810499493
userId: 5 training_loss:  0.8889706025392922
userId: 6 training_loss:  1.5978071159302125
userId: 7 training_loss:  3.8334709733540917
userId: 8 training_loss:  6.422754939755164
userId: 9 training_loss:  2.9115783685517647
userId: 10 training_loss:  1.4094708351251846
userId: 11 training_loss:  2.613434817910305
userId: 12 training_loss:  4.171940722392757
userId: 13 training_loss:  4.334635357121688
userId: 14 training_loss:  3.5531772504355756
userId: 15 training_loss:  2.192463834012375
userId: 16 training_loss:  3.5875977450245573
userId: 17 training_loss:  2.4551830496579887
userId: 18 training_loss:  3.5422052725387103
userId: 19 training_loss:  3.790336660602089
userId: 20 training_loss:  3.5525905845210657
Evaluating model...
computed_loss: 1.543820340071101
Starting round 53
userId: 0 training_loss:  4.791939887702986
userId: 1 training_loss:  4.4917752256043
userId: 2 training_loss:  2.674268433769879
userId: 3 training_loss:  4.198535148039683
userId: 4 training_loss:  3.4054904173020475
userId: 5 training_loss:  1.0002704547365493
userId: 6 training_loss:  1.6502217054301695
userId: 7 training_loss:  4.117337411506236
userId: 8 training_loss:  5.90743963336587
userId: 9 training_loss:  2.990154331587687
userId: 10 training_loss:  1.3990204115939322
userId: 11 training_loss:  2.6989288599589876
userId: 12 training_loss:  3.4675748986458204
userId: 13 training_loss:  4.166254045129917
userId: 14 training_loss:  2.79884654742145
userId: 15 training_loss:  2.2015331906523485
userId: 16 training_loss:  2.5005858184418885
userId: 17 training_loss:  2.2055758668205043
userId: 18 training_loss:  3.1867647499987677
userId: 19 training_loss:  3.789436163327417
userId: 20 training_loss:  3.8004221042282764
Evaluating model...
computed_loss: 1.4747950186605092
Starting round 54
userId: 0 training_loss:  4.455276018369234
userId: 1 training_loss:  4.1034591509084235
userId: 2 training_loss:  3.292919836140521
userId: 3 training_loss:  3.778597146971729
userId: 4 training_loss:  3.4021122045477816
userId: 5 training_loss:  1.0766173589725951
userId: 6 training_loss:  1.8964035399469896
userId: 7 training_loss:  3.7221824810683244
userId: 8 training_loss:  6.137976167947024
userId: 9 training_loss:  2.8388471838013016
userId: 10 training_loss:  1.3130402917324606
userId: 11 training_loss:  3.191042431539188
userId: 12 training_loss:  3.1086325826315777
userId: 13 training_loss:  4.251043610595314
userId: 14 training_loss:  3.152026290557573
userId: 15 training_loss:  2.3185521314019097
userId: 16 training_loss:  2.538044515917231
userId: 17 training_loss:  2.101742138785746
userId: 18 training_loss:  3.0726721838231215
userId: 19 training_loss:  3.712572156167417
userId: 20 training_loss:  3.892506727379203
Evaluating model...
computed_loss: 1.3239380760598647
Starting round 55
userId: 0 training_loss:  4.807015989872427
userId: 1 training_loss:  4.664661444146228
userId: 2 training_loss:  2.715540578030917
userId: 3 training_loss:  4.019731209881776
userId: 4 training_loss:  3.619841532611691
userId: 5 training_loss:  0.9157353200123136
userId: 6 training_loss:  1.9912612037034567
userId: 7 training_loss:  4.174123988480546
userId: 8 training_loss:  5.478355395820157
userId: 9 training_loss:  3.9162701914568174
userId: 10 training_loss:  1.2869877568622248
userId: 11 training_loss:  2.6153687003791264
userId: 12 training_loss:  3.9008866968338536
userId: 13 training_loss:  5.423410289101991
userId: 14 training_loss:  2.7297576110554336
userId: 15 training_loss:  2.434631600017421
userId: 16 training_loss:  3.480028109796146
userId: 17 training_loss:  2.1115009597818504
userId: 18 training_loss:  2.891175216703322
userId: 19 training_loss:  3.685574644378692
userId: 20 training_loss:  4.38175047395597
Evaluating model...
computed_loss: 1.4330651901562956
Starting round 56
userId: 0 training_loss:  4.741329217395444
userId: 1 training_loss:  5.070631878146921
userId: 2 training_loss:  3.136915773138477
userId: 3 training_loss:  3.7045983219536742
userId: 4 training_loss:  2.7036139628922653
userId: 5 training_loss:  0.8977760965223396
userId: 6 training_loss:  1.7545135442318138
userId: 7 training_loss:  3.7273755703343143
userId: 8 training_loss:  4.877313896246099
userId: 9 training_loss:  2.924279265848692
userId: 10 training_loss:  1.4348638909759086
userId: 11 training_loss:  4.0475992595866455
userId: 12 training_loss:  3.9694631959043107
userId: 13 training_loss:  4.421495513830898
userId: 14 training_loss:  3.031649338218819
userId: 15 training_loss:  2.593686722540002
userId: 16 training_loss:  3.166093373069007
userId: 17 training_loss:  2.3794865380836567
userId: 18 training_loss:  3.2733822984001923
userId: 19 training_loss:  3.3005367340924368
userId: 20 training_loss:  3.556393285614895
Evaluating model...
computed_loss: 1.5379805092330592
Starting round 57
userId: 0 training_loss:  4.802475388452257
userId: 1 training_loss:  4.454520984105542
userId: 2 training_loss:  2.980365310227414
userId: 3 training_loss:  4.15858939284595
userId: 4 training_loss:  3.288697891265083
userId: 5 training_loss:  1.1594247876075794
userId: 6 training_loss:  1.787023499679306
userId: 7 training_loss:  4.164987353486842
userId: 8 training_loss:  5.845349812457054
userId: 9 training_loss:  3.212078448047773
userId: 10 training_loss:  1.171756035231727
userId: 11 training_loss:  3.714507763591796
userId: 12 training_loss:  4.202085824809425
userId: 13 training_loss:  4.99955537640823
userId: 14 training_loss:  3.018708657164868
userId: 15 training_loss:  2.1557522732563372
userId: 16 training_loss:  3.4748563198251565
userId: 17 training_loss:  2.075687123210429
userId: 18 training_loss:  3.9889442271503244
userId: 19 training_loss:  3.8801155427893326
userId: 20 training_loss:  4.455400772473147
Evaluating model...
computed_loss: 1.3930329340977852
Starting round 58
userId: 0 training_loss:  4.704133143523788
userId: 1 training_loss:  4.710679838513829
userId: 2 training_loss:  3.3676218114295637
userId: 3 training_loss:  4.09991403474417
userId: 4 training_loss:  3.368451812609249
userId: 5 training_loss:  1.0190242360193695
userId: 6 training_loss:  1.768028949222733
userId: 7 training_loss:  4.41324811238916
userId: 8 training_loss:  5.741149851892424
userId: 9 training_loss:  2.680185620135875
userId: 10 training_loss:  1.1798164756226857
userId: 11 training_loss:  3.276338911023339
userId: 12 training_loss:  4.170683193767235
userId: 13 training_loss:  4.2071060037201775
userId: 14 training_loss:  3.4696063712626612
userId: 15 training_loss:  2.237215079448327
userId: 16 training_loss:  3.0751101192785173
userId: 17 training_loss:  2.2255525825962708
userId: 18 training_loss:  3.1073899231883706
userId: 19 training_loss:  3.9360633069266457
userId: 20 training_loss:  4.357741712354407
Evaluating model...
computed_loss: 1.6880324485861882
Starting round 59
userId: 0 training_loss:  4.851472779359549
userId: 1 training_loss:  4.370056181615117
userId: 2 training_loss:  3.282108154446557
userId: 3 training_loss:  3.667871812252261
userId: 4 training_loss:  3.150121998706333
userId: 5 training_loss:  1.0500678913483017
userId: 6 training_loss:  1.7615565925393413
userId: 7 training_loss:  4.074038227791045
userId: 8 training_loss:  6.31733361112963
userId: 9 training_loss:  2.6503596529627145
userId: 10 training_loss:  1.3996869903400846
userId: 11 training_loss:  3.077278865884998
userId: 12 training_loss:  3.351969159195889
userId: 13 training_loss:  4.635772559354035
userId: 14 training_loss:  3.4394456300929734
userId: 15 training_loss:  2.332229523677051
userId: 16 training_loss:  2.8543157181111556
userId: 17 training_loss:  2.0073199749286257
userId: 18 training_loss:  3.5542998032938193
userId: 19 training_loss:  3.3652821728015327
userId: 20 training_loss:  3.6850899330536158
Evaluating model...
computed_loss: 1.4404556818956065
Starting round 60
userId: 0 training_loss:  4.896242190329377
userId: 1 training_loss:  4.757817007623987
userId: 2 training_loss:  3.1801206494081775
userId: 3 training_loss:  3.9015338013636125
userId: 4 training_loss:  2.917315409304554
userId: 5 training_loss:  1.0058146784846256
userId: 6 training_loss:  1.5397126265075343
userId: 7 training_loss:  3.956144056604198
userId: 8 training_loss:  4.859353355693921
userId: 9 training_loss:  2.605089698480496
userId: 10 training_loss:  1.3258432948487422
userId: 11 training_loss:  2.4188803097997607
userId: 12 training_loss:  3.4330112044927334
userId: 13 training_loss:  4.213530559454847
userId: 14 training_loss:  3.168920639776122
userId: 15 training_loss:  2.133678322607206
userId: 16 training_loss:  2.8504727920940502
userId: 17 training_loss:  1.8110311147161924
userId: 18 training_loss:  3.0167658585300865
userId: 19 training_loss:  3.434693051903948
userId: 20 training_loss:  4.076886635352
Evaluating model...
computed_loss: 1.5292311764899877
Starting round 61
userId: 0 training_loss:  4.986241648734266
userId: 1 training_loss:  4.397931701230699
userId: 2 training_loss:  3.2353751773689607
userId: 3 training_loss:  4.452034819982653
userId: 4 training_loss:  2.970493932399785
userId: 5 training_loss:  1.1024976345958888
userId: 6 training_loss:  1.8570554456107868
userId: 7 training_loss:  3.729881283787294
userId: 8 training_loss:  5.442894608073938
userId: 9 training_loss:  3.180104178942544
userId: 10 training_loss:  1.3386505895114267
userId: 11 training_loss:  2.785037162424794
userId: 12 training_loss:  3.4440544495605416
userId: 13 training_loss:  4.690331254363699
userId: 14 training_loss:  3.12380414184066
userId: 15 training_loss:  1.8470076743595747
userId: 16 training_loss:  3.185111286646715
userId: 17 training_loss:  2.126140547575004
userId: 18 training_loss:  4.021132331793906
userId: 19 training_loss:  3.9815518886919223
userId: 20 training_loss:  4.136672221988054
Evaluating model...
computed_loss: 1.4781862157306633
Starting round 62
userId: 0 training_loss:  5.424211487561622
userId: 1 training_loss:  5.083890208281633
userId: 2 training_loss:  2.7692560868442913
userId: 3 training_loss:  4.052355191115797
userId: 4 training_loss:  3.2401717385416626
userId: 5 training_loss:  0.9007111943766931
userId: 6 training_loss:  1.5807899336843656
userId: 7 training_loss:  3.649184377640586
userId: 8 training_loss:  5.622180725515341
userId: 9 training_loss:  3.017954768045901
userId: 10 training_loss:  1.2100648104085745
userId: 11 training_loss:  2.8294207042013366
userId: 12 training_loss:  3.927308603964769
userId: 13 training_loss:  4.8179941741808054
userId: 14 training_loss:  2.8531733281592375
userId: 15 training_loss:  2.060235798769495
userId: 16 training_loss:  2.98541966450614
userId: 17 training_loss:  2.415290016662886
userId: 18 training_loss:  3.511556651970551
userId: 19 training_loss:  4.296391887575316
userId: 20 training_loss:  3.705025672928511
Evaluating model...
computed_loss: 1.550417355994356
Starting round 63
userId: 0 training_loss:  5.166005281092065
userId: 1 training_loss:  4.610891425493492
userId: 2 training_loss:  3.3537427839509406
userId: 3 training_loss:  3.610692769712506
userId: 4 training_loss:  3.4832481319850084
userId: 5 training_loss:  1.1022767848208288
userId: 6 training_loss:  1.6689245833649977
userId: 7 training_loss:  4.200820616431424
userId: 8 training_loss:  5.326581292507303
userId: 9 training_loss:  2.5617790393245063
userId: 10 training_loss:  1.3288110303607983
userId: 11 training_loss:  2.882238866146367
userId: 12 training_loss:  4.327846293174137
userId: 13 training_loss:  4.2013378520826645
userId: 14 training_loss:  2.8444746104803165
userId: 15 training_loss:  2.4140650061838596
userId: 16 training_loss:  3.4038484542033194
userId: 17 training_loss:  2.1147406554541286
userId: 18 training_loss:  3.347837792829582
userId: 19 training_loss:  3.584922288145129
userId: 20 training_loss:  4.43144951078449
Evaluating model...
computed_loss: 1.3679708239544208
Starting round 64
userId: 0 training_loss:  5.460173038481129
userId: 1 training_loss:  4.631082210814351
userId: 2 training_loss:  3.875285559127208
userId: 3 training_loss:  3.7583617345050833
userId: 4 training_loss:  3.6101286873802985
userId: 5 training_loss:  1.1239108059981338
userId: 6 training_loss:  1.8389007169462324
userId: 7 training_loss:  3.7445088759129064
userId: 8 training_loss:  5.188739257370443
userId: 9 training_loss:  4.003363809259288
userId: 10 training_loss:  1.3833792658660158
userId: 11 training_loss:  3.1268456723720135
userId: 12 training_loss:  3.792659491588764
userId: 13 training_loss:  4.951545390064086
userId: 14 training_loss:  3.8530905702756284
userId: 15 training_loss:  2.0805426486520213
userId: 16 training_loss:  2.8277426089667115
userId: 17 training_loss:  2.3976873983410707
userId: 18 training_loss:  3.094503358795218
userId: 19 training_loss:  3.230303763194569
userId: 20 training_loss:  3.4922748652224023
Evaluating model...
computed_loss: 1.6729314416143886
Starting round 65
userId: 0 training_loss:  4.377535423627282
userId: 1 training_loss:  4.590363779138391
userId: 2 training_loss:  3.613973120349338
userId: 3 training_loss:  3.8726544034213335
userId: 4 training_loss:  3.7108886255200986
userId: 5 training_loss:  1.082678775092933
userId: 6 training_loss:  1.7489674243775635
userId: 7 training_loss:  3.924700434826229
userId: 8 training_loss:  4.970778533776313
userId: 9 training_loss:  3.3600595646431315
userId: 10 training_loss:  1.4716236197934818
userId: 11 training_loss:  3.0659108731653855
userId: 12 training_loss:  3.960778513681882
userId: 13 training_loss:  4.412046781110796
userId: 14 training_loss:  3.274821495866795
userId: 15 training_loss:  2.3627408753197203
userId: 16 training_loss:  3.261206839790512
userId: 17 training_loss:  2.6529199699867205
userId: 18 training_loss:  3.4685462238304217
userId: 19 training_loss:  3.752246102686282
userId: 20 training_loss:  3.7855044109883176
Evaluating model...
computed_loss: 1.4086004373199155
Starting round 66
userId: 0 training_loss:  4.549607921209284
userId: 1 training_loss:  5.184642307059791
userId: 2 training_loss:  2.747462108532519
userId: 3 training_loss:  4.256656871797474
userId: 4 training_loss:  3.49772667873738
userId: 5 training_loss:  1.215501954665552
userId: 6 training_loss:  1.7001970441244978
userId: 7 training_loss:  4.469191251031019
userId: 8 training_loss:  6.456629167879285
userId: 9 training_loss:  2.8709958910991777
userId: 10 training_loss:  1.3794400670375966
userId: 11 training_loss:  3.9254296789479945
userId: 12 training_loss:  3.515151073219402
userId: 13 training_loss:  4.764944155263851
userId: 14 training_loss:  2.9704762585851703
userId: 15 training_loss:  1.9799649985604677
userId: 16 training_loss:  3.030020484101944
userId: 17 training_loss:  2.178044234872398
userId: 18 training_loss:  3.2836192653056577
userId: 19 training_loss:  4.687125743713138
userId: 20 training_loss:  4.67322089726043
Evaluating model...
computed_loss: 1.3190379555652751
Starting round 67
userId: 0 training_loss:  4.566537716407633
userId: 1 training_loss:  4.817260639752442
userId: 2 training_loss:  2.8801739503528307
userId: 3 training_loss:  3.6509451445966734
userId: 4 training_loss:  2.9344022527132614
userId: 5 training_loss:  1.033041488039554
userId: 6 training_loss:  1.5717852082975916
userId: 7 training_loss:  4.087909094263443
userId: 8 training_loss:  5.3001998865375075
userId: 9 training_loss:  3.088216502380175
userId: 10 training_loss:  1.306875753291163
userId: 11 training_loss:  2.5606334307287044
userId: 12 training_loss:  4.172588556152891
userId: 13 training_loss:  4.511324646146839
userId: 14 training_loss:  3.803089473679787
userId: 15 training_loss:  2.447932852133351
userId: 16 training_loss:  2.7089031879442302
userId: 17 training_loss:  2.104769949200693
userId: 18 training_loss:  3.665727288250306
userId: 19 training_loss:  3.563382755226164
userId: 20 training_loss:  4.086429065968317
Evaluating model...
computed_loss: 1.355275378766897
Starting round 68
userId: 0 training_loss:  5.27556683214981
userId: 1 training_loss:  4.833614350612409
userId: 2 training_loss:  3.087070813860079
userId: 3 training_loss:  3.72830617387019
userId: 4 training_loss:  3.174496223486744
userId: 5 training_loss:  0.9765150268803862
userId: 6 training_loss:  1.5823459611553807
userId: 7 training_loss:  3.861558380039402
userId: 8 training_loss:  5.746253457953176
userId: 9 training_loss:  3.164961272578522
userId: 10 training_loss:  1.3861029374157212
userId: 11 training_loss:  3.0138388129628852
userId: 12 training_loss:  3.7016524223134666
userId: 13 training_loss:  4.237401696245439
userId: 14 training_loss:  3.7189127926531107
userId: 15 training_loss:  2.2811316758234392
userId: 16 training_loss:  2.820578999330022
userId: 17 training_loss:  2.2207350777149513
userId: 18 training_loss:  3.5115442089792817
userId: 19 training_loss:  4.2680752553905394
userId: 20 training_loss:  3.9049946823709263
Evaluating model...
computed_loss: 1.5063392240728801
Starting round 69
userId: 0 training_loss:  5.269149384520561
userId: 1 training_loss:  4.22953680059095
userId: 2 training_loss:  2.7699367080386854
userId: 3 training_loss:  4.1672445418336945
userId: 4 training_loss:  2.7722627034537317
userId: 5 training_loss:  1.0721919478197253
userId: 6 training_loss:  1.6619774976248916
userId: 7 training_loss:  4.155034068140341
userId: 8 training_loss:  5.700890153784501
userId: 9 training_loss:  3.7740881734244467
userId: 10 training_loss:  1.3760566275578996
userId: 11 training_loss:  2.6650658962712734
userId: 12 training_loss:  3.6809757304008444
userId: 13 training_loss:  4.348092398362093
userId: 14 training_loss:  3.0458641932966044
userId: 15 training_loss:  2.6560085610535555
userId: 16 training_loss:  3.100439402214129
userId: 17 training_loss:  2.2803355780393835
userId: 18 training_loss:  3.1316823178982838
userId: 19 training_loss:  3.1787122344006575
userId: 20 training_loss:  3.998429205006225
Evaluating model...
computed_loss: 1.4178400494553154
Starting round 70
userId: 0 training_loss:  4.838286699380386
userId: 1 training_loss:  4.689445279657271
userId: 2 training_loss:  2.9680907341460143
userId: 3 training_loss:  3.7373836684303754
userId: 4 training_loss:  3.4660273179480976
userId: 5 training_loss:  1.12149765656223
userId: 6 training_loss:  1.517074324979066
userId: 7 training_loss:  3.9384574113608144
userId: 8 training_loss:  5.2583253006775434
userId: 9 training_loss:  2.8430869448809677
userId: 10 training_loss:  1.3356348638261741
userId: 11 training_loss:  3.1402084153131753
userId: 12 training_loss:  3.356815864685089
userId: 13 training_loss:  4.78328047885646
userId: 14 training_loss:  3.1088780197865304
userId: 15 training_loss:  1.983547074240113
userId: 16 training_loss:  3.946868918763647
userId: 17 training_loss:  2.2067184213352045
userId: 18 training_loss:  2.997783212048178
userId: 19 training_loss:  3.941889735601234
userId: 20 training_loss:  4.182884110190686
Evaluating model...
computed_loss: 1.493444065031423
Starting round 71
userId: 0 training_loss:  5.689165732803068
userId: 1 training_loss:  5.3089113776171
userId: 2 training_loss:  3.5257348627029246
userId: 3 training_loss:  4.325324899185583
userId: 4 training_loss:  2.864599197965596
userId: 5 training_loss:  1.1694761123315047
userId: 6 training_loss:  1.769153779951394
userId: 7 training_loss:  3.8721920932238603
userId: 8 training_loss:  5.667264745247743
userId: 9 training_loss:  3.4876327367941387
userId: 10 training_loss:  1.393084960454942
userId: 11 training_loss:  2.6715891950813204
userId: 12 training_loss:  3.787629624320509
userId: 13 training_loss:  4.40173620438608
userId: 14 training_loss:  2.9750100437371962
userId: 15 training_loss:  2.2624512578008504
userId: 16 training_loss:  3.1799462472825306
userId: 17 training_loss:  1.938298314092998
userId: 18 training_loss:  2.98453908650241
userId: 19 training_loss:  3.845469490466699
userId: 20 training_loss:  3.202119017382276
Evaluating model...
computed_loss: 1.4937766195288704
Starting round 72
userId: 0 training_loss:  5.023007178302083
userId: 1 training_loss:  3.8272325647891874
userId: 2 training_loss:  3.564265430980762
userId: 3 training_loss:  3.688606515981847
userId: 4 training_loss:  2.9985256323821483
userId: 5 training_loss:  1.1248289224870942
userId: 6 training_loss:  1.720071427052948
userId: 7 training_loss:  4.184827567633723
userId: 8 training_loss:  5.848685249299004
userId: 9 training_loss:  3.3925483913938193
userId: 10 training_loss:  1.447393280625849
userId: 11 training_loss:  2.9415003421673083
userId: 12 training_loss:  3.629084416079338
userId: 13 training_loss:  4.469068912680571
userId: 14 training_loss:  3.6330412591964554
userId: 15 training_loss:  2.1475916824344377
userId: 16 training_loss:  3.1997446999499077
userId: 17 training_loss:  2.2315160542641053
userId: 18 training_loss:  3.151839924320485
userId: 19 training_loss:  4.320134457157218
userId: 20 training_loss:  3.761203694900008
Evaluating model...
computed_loss: 1.4135392762702044
Starting round 73
userId: 0 training_loss:  4.751872810601893
userId: 1 training_loss:  5.258869796501644
userId: 2 training_loss:  2.849459774402168
userId: 3 training_loss:  3.5735754357535625
userId: 4 training_loss:  3.8312658803704935
userId: 5 training_loss:  0.9790579826097924
userId: 6 training_loss:  1.8518298486276952
userId: 7 training_loss:  3.9272009062137365
userId: 8 training_loss:  4.894529049970821
userId: 9 training_loss:  2.6204271301660933
userId: 10 training_loss:  1.4584870146398698
userId: 11 training_loss:  2.981335712657164
userId: 12 training_loss:  3.8779029154066613
userId: 13 training_loss:  4.167562952740619
userId: 14 training_loss:  3.4995634963493756
userId: 15 training_loss:  2.1240482421440294
userId: 16 training_loss:  2.6957095054652798
userId: 17 training_loss:  1.9743260397961588
userId: 18 training_loss:  3.205163786531828
userId: 19 training_loss:  3.4657278669934746
userId: 20 training_loss:  4.417042575870026
Evaluating model...
computed_loss: 1.2852320744718166
Starting round 74
userId: 0 training_loss:  5.2966957732763476
userId: 1 training_loss:  4.000685699811323
userId: 2 training_loss:  3.0547928784725835
userId: 3 training_loss:  3.922504384705083
userId: 4 training_loss:  3.032523716986186
userId: 5 training_loss:  1.0778912190458265
userId: 6 training_loss:  1.5390688727257795
userId: 7 training_loss:  4.029338238453908
userId: 8 training_loss:  5.318969682883623
userId: 9 training_loss:  3.098078034142388
userId: 10 training_loss:  1.2127441096470755
userId: 11 training_loss:  4.89937041670762
userId: 12 training_loss:  3.1258294475867876
userId: 13 training_loss:  3.883384439987482
userId: 14 training_loss:  3.999491821829735
userId: 15 training_loss:  2.1276884916994594
userId: 16 training_loss:  2.503089180460084
userId: 17 training_loss:  2.056362247187771
userId: 18 training_loss:  3.4210979043496885
userId: 19 training_loss:  3.7739392360573176
userId: 20 training_loss:  3.8246677552423947
Evaluating model...
computed_loss: 1.386294065275782
Starting round 75
userId: 0 training_loss:  4.8309929110950165
userId: 1 training_loss:  5.781160056812692
userId: 2 training_loss:  3.1692420586171965
userId: 3 training_loss:  4.105195163326623
userId: 4 training_loss:  3.413450387462371
userId: 5 training_loss:  1.149735534640684
userId: 6 training_loss:  1.9592255749617433
userId: 7 training_loss:  3.899761952083916
userId: 8 training_loss:  5.776967355501663
userId: 9 training_loss:  3.1365883539532424
userId: 10 training_loss:  1.319342725801259
userId: 11 training_loss:  3.1027181437366926
userId: 12 training_loss:  3.698511143229058
userId: 13 training_loss:  4.3717654524432294
userId: 14 training_loss:  3.3274176384434577
userId: 15 training_loss:  2.218847491154157
userId: 16 training_loss:  3.086610576512535
userId: 17 training_loss:  2.5215743897035567
userId: 18 training_loss:  3.5904250817247685
userId: 19 training_loss:  3.911548042764385
userId: 20 training_loss:  3.2907275725044665
Evaluating model...
computed_loss: 1.402767855538068
Starting round 76
userId: 0 training_loss:  5.00849621305514
userId: 1 training_loss:  4.051981887205797
userId: 2 training_loss:  2.987970496047418
userId: 3 training_loss:  3.31208354006226
userId: 4 training_loss:  3.5342093609290544
userId: 5 training_loss:  1.1268002098174374
userId: 6 training_loss:  1.995372573930456
userId: 7 training_loss:  4.288755535529446
userId: 8 training_loss:  5.550302701998392
userId: 9 training_loss:  2.8716606277282137
userId: 10 training_loss:  1.2565135863248127
userId: 11 training_loss:  3.1284307843211208
userId: 12 training_loss:  3.3093833907215213
userId: 13 training_loss:  4.210438801322033
userId: 14 training_loss:  3.693419773555432
userId: 15 training_loss:  2.1252818515309357
userId: 16 training_loss:  2.543411948939207
userId: 17 training_loss:  1.9034948648571046
userId: 18 training_loss:  3.1851508883193014
userId: 19 training_loss:  3.6154323844431473
userId: 20 training_loss:  3.2574891205741885
Evaluating model...
computed_loss: 1.2841427835895818
Starting round 77
userId: 0 training_loss:  5.137928302752706
userId: 1 training_loss:  4.0954509123551315
userId: 2 training_loss:  2.8369587316729556
userId: 3 training_loss:  4.351347991562359
userId: 4 training_loss:  3.118486485005884
userId: 5 training_loss:  1.1184702807029392
userId: 6 training_loss:  1.7717073843665987
userId: 7 training_loss:  3.6278593193045383
userId: 8 training_loss:  5.7041838765155415
userId: 9 training_loss:  3.3583476573062496
userId: 10 training_loss:  1.3169395966453936
userId: 11 training_loss:  2.6585312114716118
userId: 12 training_loss:  3.9868334675781734
userId: 13 training_loss:  4.86909062679142
userId: 14 training_loss:  3.2240459642287
userId: 15 training_loss:  2.2749340111253007
userId: 16 training_loss:  2.894106736584029
userId: 17 training_loss:  2.0918699142359585
userId: 18 training_loss:  3.5902438796207425
userId: 19 training_loss:  4.16877624568435
userId: 20 training_loss:  4.580145552531451
Evaluating model...
computed_loss: 1.340384024113022
Starting round 78
userId: 0 training_loss:  4.913988267483024
userId: 1 training_loss:  4.54743691874335
userId: 2 training_loss:  3.190059024253022
userId: 3 training_loss:  3.325260706609579
userId: 4 training_loss:  3.2043835617300482
userId: 5 training_loss:  0.9065388011280966
userId: 6 training_loss:  1.6505445471372902
userId: 7 training_loss:  3.63465268586346
userId: 8 training_loss:  5.696901850897249
userId: 9 training_loss:  3.0784762223231903
userId: 10 training_loss:  1.2643742916466436
userId: 11 training_loss:  2.1839448595245137
userId: 12 training_loss:  4.12118513341821
userId: 13 training_loss:  3.5803293998250076
userId: 14 training_loss:  4.168734916784826
userId: 15 training_loss:  1.9153449581605695
userId: 16 training_loss:  4.291603020617062
userId: 17 training_loss:  1.719158035000874
userId: 18 training_loss:  3.3721366344825654
userId: 19 training_loss:  3.332244521888582
userId: 20 training_loss:  4.050802869420453
Evaluating model...
computed_loss: 1.5655449230389695
Starting round 79
userId: 0 training_loss:  5.303469392382932
userId: 1 training_loss:  4.2497561903383785
userId: 2 training_loss:  3.297436945830598
userId: 3 training_loss:  5.009243504003692
userId: 4 training_loss:  3.3399581905216067
userId: 5 training_loss:  1.206022640032569
userId: 6 training_loss:  1.9543703956053804
userId: 7 training_loss:  4.243380171635122
userId: 8 training_loss:  5.626053229830197
userId: 9 training_loss:  2.869059452711067
userId: 10 training_loss:  1.469836307709055
userId: 11 training_loss:  3.352672230855778
userId: 12 training_loss:  3.8099292238139717
userId: 13 training_loss:  3.98079014144946
userId: 14 training_loss:  3.689214943186104
userId: 15 training_loss:  2.320418491489151
userId: 16 training_loss:  3.2422838533447433
userId: 17 training_loss:  2.064647781179371
userId: 18 training_loss:  3.2827204099114207
userId: 19 training_loss:  3.6274640216393204
userId: 20 training_loss:  3.3964122880298246
Evaluating model...
computed_loss: 1.2353359974299076
Starting round 80
userId: 0 training_loss:  4.783753457700971
userId: 1 training_loss:  5.3960226151107715
userId: 2 training_loss:  2.5809170749887356
userId: 3 training_loss:  3.472020731495256
userId: 4 training_loss:  3.2663664257068836
userId: 5 training_loss:  1.251475391155696
userId: 6 training_loss:  1.6932175042780209
userId: 7 training_loss:  3.812588043600352
userId: 8 training_loss:  4.868618501594634
userId: 9 training_loss:  3.400421924604577
userId: 10 training_loss:  1.2199414891629063
userId: 11 training_loss:  2.9971964989317903
userId: 12 training_loss:  3.53538734484588
userId: 13 training_loss:  3.9096990149792994
userId: 14 training_loss:  3.377501148860632
userId: 15 training_loss:  2.008489567567692
userId: 16 training_loss:  2.1649668842750227
userId: 17 training_loss:  2.4019673633807894
userId: 18 training_loss:  3.173491999144363
userId: 19 training_loss:  3.721965945581047
userId: 20 training_loss:  3.7365106281229665
Evaluating model...
computed_loss: 1.4408966216842027
Starting round 81
userId: 0 training_loss:  5.365963259621753
userId: 1 training_loss:  4.7126487675400615
userId: 2 training_loss:  3.094322627219842
userId: 3 training_loss:  4.156282953300678
userId: 4 training_loss:  3.140230634928529
userId: 5 training_loss:  1.0857259981196286
userId: 6 training_loss:  1.6037083746857583
userId: 7 training_loss:  3.881223081316186
userId: 8 training_loss:  5.50119249467683
userId: 9 training_loss:  3.431462629099508
userId: 10 training_loss:  1.3487179479642415
userId: 11 training_loss:  3.1448992889648233
userId: 12 training_loss:  3.8348471969991893
userId: 13 training_loss:  3.8057857767351364
userId: 14 training_loss:  3.3751281221367093
userId: 15 training_loss:  2.310474037920634
userId: 16 training_loss:  3.0395314239383855
userId: 17 training_loss:  2.14911120690065
userId: 18 training_loss:  2.9381898548669856
userId: 19 training_loss:  3.7230507632936494
userId: 20 training_loss:  4.441890375370905
Evaluating model...
computed_loss: 1.2573777064865659
Starting round 82
userId: 0 training_loss:  4.448795331852201
userId: 1 training_loss:  4.606602146298398
userId: 2 training_loss:  2.967894436072747
userId: 3 training_loss:  3.190649196664866
userId: 4 training_loss:  2.963194801431909
userId: 5 training_loss:  1.0053969378741503
userId: 6 training_loss:  1.6997094478063226
userId: 7 training_loss:  4.091081710403656
userId: 8 training_loss:  6.081999234457517
userId: 9 training_loss:  3.0529396978000687
userId: 10 training_loss:  1.3395433776907226
userId: 11 training_loss:  3.0463820068107306
userId: 12 training_loss:  3.5771019204506764
userId: 13 training_loss:  4.2555619171043135
userId: 14 training_loss:  3.790563487417349
userId: 15 training_loss:  2.0445881950806957
userId: 16 training_loss:  2.5709794698052137
userId: 17 training_loss:  2.1639589873724283
userId: 18 training_loss:  3.323988588629028
userId: 19 training_loss:  3.911846804054077
userId: 20 training_loss:  4.592102362727388
Evaluating model...
computed_loss: 1.4160881778385768
Starting round 83
userId: 0 training_loss:  5.237782223368817
userId: 1 training_loss:  3.7781468954706354
userId: 2 training_loss:  2.724922883229996
userId: 3 training_loss:  4.21129823136475
userId: 4 training_loss:  3.205045997909052
userId: 5 training_loss:  1.0988655404352072
userId: 6 training_loss:  1.6605619368463447
userId: 7 training_loss:  4.171178107284107
userId: 8 training_loss:  5.486260050500746
userId: 9 training_loss:  3.3426126486393364
userId: 10 training_loss:  1.3192836879711127
userId: 11 training_loss:  3.268532631479836
userId: 12 training_loss:  3.70500240761751
userId: 13 training_loss:  4.722750228774255
userId: 14 training_loss:  2.829836625216084
userId: 15 training_loss:  2.0829243781345594
userId: 16 training_loss:  2.7117204061816067
userId: 17 training_loss:  1.8752555498795611
userId: 18 training_loss:  3.1520740551258752
userId: 19 training_loss:  4.129763535737113
userId: 20 training_loss:  4.529496763674619
Evaluating model...
computed_loss: 1.4080033801307894
Starting round 84
userId: 0 training_loss:  5.058764684934888
userId: 1 training_loss:  4.126228721766902
userId: 2 training_loss:  2.946091833068671
userId: 3 training_loss:  3.4440698390549436
userId: 4 training_loss:  3.033247316547091
userId: 5 training_loss:  1.071777992330272
userId: 6 training_loss:  1.7500997748455778
userId: 7 training_loss:  4.404994065691649
userId: 8 training_loss:  5.7610168789544
userId: 9 training_loss:  2.9128170167713185
userId: 10 training_loss:  1.4229064168915244
userId: 11 training_loss:  3.359785853108457
userId: 12 training_loss:  3.402799826029881
userId: 13 training_loss:  4.757918106551951
userId: 14 training_loss:  3.335883551687131
userId: 15 training_loss:  1.9606380413651112
userId: 16 training_loss:  3.2945964998966
userId: 17 training_loss:  2.0638294189666118
userId: 18 training_loss:  3.116184155395102
userId: 19 training_loss:  3.405066923523622
userId: 20 training_loss:  3.3169448157153987
Evaluating model...
computed_loss: 1.3259780540767578
Starting round 85
userId: 0 training_loss:  4.7672249226368155
userId: 1 training_loss:  3.8392287765049624
userId: 2 training_loss:  2.909336378652146
userId: 3 training_loss:  3.443922248387735
userId: 4 training_loss:  3.4137747830504104
userId: 5 training_loss:  1.1230188056988022
userId: 6 training_loss:  1.6754763883003652
userId: 7 training_loss:  3.7711823889302876
userId: 8 training_loss:  5.643975734974427
userId: 9 training_loss:  3.0903823045651917
userId: 10 training_loss:  1.29852628524642
userId: 11 training_loss:  3.0829838260459073
userId: 12 training_loss:  4.4548428086692295
userId: 13 training_loss:  3.5600494536640026
userId: 14 training_loss:  3.041571872575578
userId: 15 training_loss:  2.117285755451017
userId: 16 training_loss:  2.986245605966971
userId: 17 training_loss:  2.2829687814826207
userId: 18 training_loss:  3.2867987624394486
userId: 19 training_loss:  3.2848719758044935
userId: 20 training_loss:  4.073840267116727
Evaluating model...
computed_loss: 1.3470976467307483
Starting round 86
userId: 0 training_loss:  4.976520111452961
userId: 1 training_loss:  4.558696199261833
userId: 2 training_loss:  2.9854728818739558
userId: 3 training_loss:  4.057820416863907
userId: 4 training_loss:  2.642741078673585
userId: 5 training_loss:  1.0352075610516764
userId: 6 training_loss:  1.7628108201195443
userId: 7 training_loss:  3.742393774392957
userId: 8 training_loss:  5.487098033212816
userId: 9 training_loss:  3.501832907819682
userId: 10 training_loss:  1.3629427418845403
userId: 11 training_loss:  2.6254164577152745
userId: 12 training_loss:  4.156772963200597
userId: 13 training_loss:  4.684106880099681
userId: 14 training_loss:  3.002185751715884
userId: 15 training_loss:  2.3658135537361478
userId: 16 training_loss:  2.9928281725608707
userId: 17 training_loss:  2.372401268568261
userId: 18 training_loss:  3.1931164172020914
userId: 19 training_loss:  3.4923206741114647
userId: 20 training_loss:  3.6049885949670766
Evaluating model...
computed_loss: 1.49813772329989
Starting round 87
userId: 0 training_loss:  5.329134924138362
userId: 1 training_loss:  4.262832452056584
userId: 2 training_loss:  2.844610481391977
userId: 3 training_loss:  4.1341262057853125
userId: 4 training_loss:  2.676734767166813
userId: 5 training_loss:  1.137235016639242
userId: 6 training_loss:  1.7796327738068531
userId: 7 training_loss:  3.966070333770836
userId: 8 training_loss:  5.86612081344643
userId: 9 training_loss:  2.5500499802419183
userId: 10 training_loss:  1.2435362527822669
userId: 11 training_loss:  2.706562988348437
userId: 12 training_loss:  3.641718463276649
userId: 13 training_loss:  4.155785507239501
userId: 14 training_loss:  3.1213954101321146
userId: 15 training_loss:  2.5122705850467493
userId: 16 training_loss:  2.613680696126271
userId: 17 training_loss:  2.1119016585159285
userId: 18 training_loss:  3.55132850910365
userId: 19 training_loss:  4.295127639802103
userId: 20 training_loss:  3.8539340886019255
Evaluating model...
computed_loss: 1.3106068849317931
Starting round 88
userId: 0 training_loss:  4.745532594271433
userId: 1 training_loss:  4.660394435161118
userId: 2 training_loss:  2.9526328135616877
userId: 3 training_loss:  3.7415392234304656
userId: 4 training_loss:  3.1532836537352074
userId: 5 training_loss:  0.9275293530649631
userId: 6 training_loss:  1.6567281361979824
userId: 7 training_loss:  4.182002158707742
userId: 8 training_loss:  5.352415936700384
userId: 9 training_loss:  2.7396814175658477
userId: 10 training_loss:  1.2566775496621516
userId: 11 training_loss:  2.9581541049419013
userId: 12 training_loss:  3.36660622882939
userId: 13 training_loss:  4.907062110620929
userId: 14 training_loss:  2.6782459998147288
userId: 15 training_loss:  2.038000333301126
userId: 16 training_loss:  4.073443236926343
userId: 17 training_loss:  1.767808927185801
userId: 18 training_loss:  3.0537542289562722
userId: 19 training_loss:  3.002366621361083
userId: 20 training_loss:  3.814165685024592
Evaluating model...
computed_loss: 1.2874990902234826
Starting round 89
userId: 0 training_loss:  4.828925404855923
userId: 1 training_loss:  4.876057714282487
userId: 2 training_loss:  3.2460833188039593
userId: 3 training_loss:  3.508751926054147
userId: 4 training_loss:  2.72128204116093
userId: 5 training_loss:  1.0835527799045122
userId: 6 training_loss:  1.5746426248370649
userId: 7 training_loss:  3.6786624108692023
userId: 8 training_loss:  5.510629532961238
userId: 9 training_loss:  2.8819680148063758
userId: 10 training_loss:  1.2746781474003157
userId: 11 training_loss:  3.499495166671256
userId: 12 training_loss:  3.3839153059447895
userId: 13 training_loss:  3.7576401986015724
userId: 14 training_loss:  3.6399160781707813
userId: 15 training_loss:  1.8790069174627568
userId: 16 training_loss:  2.9567950304836925
userId: 17 training_loss:  2.2989823657387842
userId: 18 training_loss:  3.36667927770637
userId: 19 training_loss:  4.3441510101075345
userId: 20 training_loss:  3.888866423247822
Evaluating model...
computed_loss: 1.3689924229602117
Starting round 90
userId: 0 training_loss:  5.058898484159566
userId: 1 training_loss:  4.219553235751174
userId: 2 training_loss:  3.3939065790071212
userId: 3 training_loss:  3.4724896472801063
userId: 4 training_loss:  2.99101816108705
userId: 5 training_loss:  1.1602996919099413
userId: 6 training_loss:  1.6741119045817563
userId: 7 training_loss:  3.724631834461042
userId: 8 training_loss:  5.300315794018241
userId: 9 training_loss:  4.199936949889539
userId: 10 training_loss:  1.4504793527832802
userId: 11 training_loss:  3.158496590870657
userId: 12 training_loss:  3.125189241912158
userId: 13 training_loss:  4.652209419102447
userId: 14 training_loss:  3.0514024837077187
userId: 15 training_loss:  2.3778014710938145
userId: 16 training_loss:  4.14777973666431
userId: 17 training_loss:  2.328012161677851
userId: 18 training_loss:  3.4217488559157787
userId: 19 training_loss:  3.5204971110695182
userId: 20 training_loss:  3.4134750123952076
Evaluating model...
computed_loss: 1.3662511791336993
Starting round 91
userId: 0 training_loss:  5.488182685812971
userId: 1 training_loss:  4.66553979902219
userId: 2 training_loss:  2.544044739346747
userId: 3 training_loss:  4.140536379365286
userId: 4 training_loss:  2.820916786273573
userId: 5 training_loss:  1.0225375847950766
userId: 6 training_loss:  1.6936191446494253
userId: 7 training_loss:  4.457219163700552
userId: 8 training_loss:  5.804441900391169
userId: 9 training_loss:  3.1177056928301345
userId: 10 training_loss:  1.3138762542740494
userId: 11 training_loss:  3.471413072035675
userId: 12 training_loss:  3.3731394315559533
userId: 13 training_loss:  5.083269830671032
userId: 14 training_loss:  3.192650211680024
userId: 15 training_loss:  2.21819568723718
userId: 16 training_loss:  3.470631312395234
userId: 17 training_loss:  2.1022460013676216
userId: 18 training_loss:  3.748284190519791
userId: 19 training_loss:  4.121755321231221
userId: 20 training_loss:  3.08517806964747
Evaluating model...
computed_loss: 1.2826729417540574
Starting round 92
userId: 0 training_loss:  5.602209911972837
userId: 1 training_loss:  4.198756745069402
userId: 2 training_loss:  2.6925516809981516
userId: 3 training_loss:  3.374019725610779
userId: 4 training_loss:  2.948274289417579
userId: 5 training_loss:  0.863191364527139
userId: 6 training_loss:  1.5949171264147304
userId: 7 training_loss:  4.027446284773242
userId: 8 training_loss:  5.426232388386177
userId: 9 training_loss:  3.0824832563981865
userId: 10 training_loss:  1.3042862151003907
userId: 11 training_loss:  3.394735575623205
userId: 12 training_loss:  4.121392379332875
userId: 13 training_loss:  4.7483568601451065
userId: 14 training_loss:  3.6435297690134156
userId: 15 training_loss:  2.3278406047234284
userId: 16 training_loss:  2.7712941983918933
userId: 17 training_loss:  2.147458819361369
userId: 18 training_loss:  3.3828095124940796
userId: 19 training_loss:  2.998227203801261
userId: 20 training_loss:  4.015637019828302
Evaluating model...
computed_loss: 1.3401407543924744
Starting round 93
userId: 0 training_loss:  5.199025315350497
userId: 1 training_loss:  4.512186778982866
userId: 2 training_loss:  3.5643654696322273
userId: 3 training_loss:  3.607497592406747
userId: 4 training_loss:  2.811099685815951
userId: 5 training_loss:  1.0190265794576905
userId: 6 training_loss:  1.8285081883861676
userId: 7 training_loss:  4.457234248085858
userId: 8 training_loss:  5.486118229228374
userId: 9 training_loss:  2.660552732812276
userId: 10 training_loss:  1.5081482165537985
userId: 11 training_loss:  2.9826508806228396
userId: 12 training_loss:  4.935715799724176
userId: 13 training_loss:  4.100735958318101
userId: 14 training_loss:  3.2017054027906378
userId: 15 training_loss:  2.094760242239386
userId: 16 training_loss:  3.7417886551768698
userId: 17 training_loss:  2.2288418712548737
userId: 18 training_loss:  3.1605468446303044
userId: 19 training_loss:  3.405239515843339
userId: 20 training_loss:  4.082843729341731
Evaluating model...
computed_loss: 1.342783403904557
Starting round 94
userId: 0 training_loss:  5.372128030235706
userId: 1 training_loss:  4.623170148090125
userId: 2 training_loss:  3.6288665505163538
userId: 3 training_loss:  3.4978685040097766
userId: 4 training_loss:  4.076822285303815
userId: 5 training_loss:  1.1835194452531483
userId: 6 training_loss:  1.5289410092970352
userId: 7 training_loss:  4.618481593527681
userId: 8 training_loss:  5.878424421554449
userId: 9 training_loss:  2.7535788143023447
userId: 10 training_loss:  1.3590936845969774
userId: 11 training_loss:  4.420262210094775
userId: 12 training_loss:  3.692299306424668
userId: 13 training_loss:  4.237686720337505
userId: 14 training_loss:  2.928775331857548
userId: 15 training_loss:  2.2946511428594234
userId: 16 training_loss:  2.9077389733466137
userId: 17 training_loss:  2.2197851137053783
userId: 18 training_loss:  3.0904719635131324
userId: 19 training_loss:  3.107417479102036
userId: 20 training_loss:  4.192168451259748
Evaluating model...
computed_loss: 1.3854018637476553
Starting round 95
userId: 0 training_loss:  5.151878402763326
userId: 1 training_loss:  4.827927732337243
userId: 2 training_loss:  3.405994072306169
userId: 3 training_loss:  4.222436586363855
userId: 4 training_loss:  3.0674117558276093
userId: 5 training_loss:  1.1404841983874934
userId: 6 training_loss:  1.7170434571279256
userId: 7 training_loss:  3.772077101781246
userId: 8 training_loss:  5.590480444709668
userId: 9 training_loss:  3.1805131011645367
userId: 10 training_loss:  1.249363189249364
userId: 11 training_loss:  3.3358197099371893
userId: 12 training_loss:  3.7893907132849547
userId: 13 training_loss:  4.163181480224333
userId: 14 training_loss:  2.80776767458931
userId: 15 training_loss:  2.4001039598958003
userId: 16 training_loss:  2.5112189436432093
userId: 17 training_loss:  2.0952617198257637
userId: 18 training_loss:  3.369924310735447
userId: 19 training_loss:  4.122281009803173
userId: 20 training_loss:  3.8587075279277756
Evaluating model...
computed_loss: 1.330320611378951
Starting round 96
userId: 0 training_loss:  4.333588064526924
userId: 1 training_loss:  5.258783961020752
userId: 2 training_loss:  3.202595198764431
userId: 3 training_loss:  3.3784230236853845
userId: 4 training_loss:  3.37602251867013
userId: 5 training_loss:  1.2381036014127702
userId: 6 training_loss:  1.596779729151038
userId: 7 training_loss:  4.036245063058361
userId: 8 training_loss:  5.2002854486869365
userId: 9 training_loss:  2.719760606548634
userId: 10 training_loss:  1.1630526090610227
userId: 11 training_loss:  2.5872961959546
userId: 12 training_loss:  3.6778575998552396
userId: 13 training_loss:  3.9569184232731507
userId: 14 training_loss:  4.086212083855491
userId: 15 training_loss:  2.0858860373790153
userId: 16 training_loss:  2.4682683453214365
userId: 17 training_loss:  2.332318090415781
userId: 18 training_loss:  2.830803999296255
userId: 19 training_loss:  3.6241899911636013
userId: 20 training_loss:  3.695171150224038
Evaluating model...
computed_loss: 1.2605067738254567
Starting round 97
userId: 0 training_loss:  5.307936341471931
userId: 1 training_loss:  4.0901137073040355
userId: 2 training_loss:  2.8955629229148947
userId: 3 training_loss:  4.492360726831729
userId: 4 training_loss:  3.397731767420634
userId: 5 training_loss:  1.0827953372868966
userId: 6 training_loss:  1.7122866683281852
userId: 7 training_loss:  4.339815286720973
userId: 8 training_loss:  5.378289964106681
userId: 9 training_loss:  3.2787820743927703
userId: 10 training_loss:  1.2574178302384322
userId: 11 training_loss:  3.2873328183461616
userId: 12 training_loss:  4.340462627769215
userId: 13 training_loss:  4.604783150472155
userId: 14 training_loss:  3.2672208519601753
userId: 15 training_loss:  2.334519014422219
userId: 16 training_loss:  3.10920254862852
userId: 17 training_loss:  2.163777428464104
userId: 18 training_loss:  4.066185421374959
userId: 19 training_loss:  3.2799957587285085
userId: 20 training_loss:  4.005093859435175
Evaluating model...
computed_loss: 1.4174898706968673
Starting round 98
userId: 0 training_loss:  5.084774958884788
userId: 1 training_loss:  4.208914510031114
userId: 2 training_loss:  2.839823058303648
userId: 3 training_loss:  4.224044122586363
userId: 4 training_loss:  3.3912070983483873
userId: 5 training_loss:  1.1437831874837796
userId: 6 training_loss:  1.8377090886485437
userId: 7 training_loss:  4.108349794095003
userId: 8 training_loss:  4.938550066861621
userId: 9 training_loss:  3.4417170878272834
userId: 10 training_loss:  1.5521616506300802
userId: 11 training_loss:  2.8255553016489814
userId: 12 training_loss:  3.3293651803671613
userId: 13 training_loss:  4.34770607648549
userId: 14 training_loss:  2.9916252439757356
userId: 15 training_loss:  2.3813964252916806
userId: 16 training_loss:  3.2809419187435074
userId: 17 training_loss:  2.642684200639036
userId: 18 training_loss:  2.9824901215498025
userId: 19 training_loss:  3.7259032317212424
userId: 20 training_loss:  3.31921682531105
Evaluating model...
computed_loss: 1.5534155316400633
Starting round 99
userId: 0 training_loss:  5.368115119367082
userId: 1 training_loss:  4.361075653571623
userId: 2 training_loss:  2.8486037929753243
userId: 3 training_loss:  3.344996159256013
userId: 4 training_loss:  3.2750695094988496
userId: 5 training_loss:  0.9935789064819568
userId: 6 training_loss:  1.7341397024264995
userId: 7 training_loss:  4.025927390712758
userId: 8 training_loss:  5.7104411319517485
userId: 9 training_loss:  2.718903115150921
userId: 10 training_loss:  1.444926727930049
userId: 11 training_loss:  2.9222702526836377
userId: 12 training_loss:  3.645663970082135
userId: 13 training_loss:  4.056254679633085
userId: 14 training_loss:  4.08658735356422
userId: 15 training_loss:  1.941484209591669
userId: 16 training_loss:  3.0584338724168205
userId: 17 training_loss:  2.2992706296869128
userId: 18 training_loss:  3.2957622333402434
userId: 19 training_loss:  4.609416484000692
userId: 20 training_loss:  3.709133167105901
Evaluating model...
computed_loss: 1.5505789467638067
Starting round 100
userId: 0 training_loss:  5.384889153555737
userId: 1 training_loss:  4.62912391579625
userId: 2 training_loss:  3.3138885429397895
userId: 3 training_loss:  3.2995484376284
userId: 4 training_loss:  3.064139908568463
userId: 5 training_loss:  0.9911493043945786
userId: 6 training_loss:  1.7195217626545123
userId: 7 training_loss:  4.110902435254008
userId: 8 training_loss:  5.3679420550693555
userId: 9 training_loss:  3.0403596104765103
userId: 10 training_loss:  1.2628974881085724
userId: 11 training_loss:  2.787551060201161
userId: 12 training_loss:  3.752707732614001
userId: 13 training_loss:  4.280181848616278
userId: 14 training_loss:  2.792768726235973
userId: 15 training_loss:  2.3778167274276796
userId: 16 training_loss:  2.680445248624121
userId: 17 training_loss:  2.5799639462381454
userId: 18 training_loss:  3.2453664460887937
userId: 19 training_loss:  4.859754166988589
userId: 20 training_loss:  3.372401130330643
Evaluating model...
computed_loss: 1.4052560441710715
